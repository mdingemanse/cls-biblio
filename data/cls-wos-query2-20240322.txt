PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
C	Khoe, YH		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		Khoe, Yung Han			Reproducing a Morphosyntactic Tagger with a Meta-BiLSTM Model over Context Sensitive Token Encodings	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			reproduction; morphosyntactic tagging; meta-bilstm		Reproducibility is generally regarded as being a requirement for any form of experimental science. Even so, reproduction of research results is only recently beginning to be practiced and acknowledged. In the context of the REPROLANG 2020 shared task, we contribute to this trend by reproducing the work reported on by Bohnet et al. (2018) on morphosyntactic tagging. Their meta-BiLSTM model achieved state-of-the-art results across a wide range of languages. This was done by integrating sentence-level and single-word context through synchronized training by a meta-model. Our reproduction only partially confirms the main results of the paper in terms of outperforming earlier models. The results of our reproductions improve on earlier models on the morphological tagging task, but not on the part-of-speech tagging task. Furthermore, even where we improve on earlier models, we fail to match the F1-scores reported for the meta-BiLSTM model. Because we chose not to contact the original authors for our reproduction study, the uncertainty about the degree of parallelism that was achieved between the original study and our reproduction limits the value of our findings as an assessment of the reliability of the original results. At the same time, however, it underscores the relevance of our reproduction effort in regard to the reproducibility and interpretability of those findings. The discrepancies between our findings and the original results demonstrate that there is room for improvement in many aspects of reporting regarding the reproducibility of the experiments. In addition, we suggest that different reporting choices could improve the interpretability of the results.	[Khoe, Yung Han] Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands	Radboud University Nijmegen	Khoe, YH (corresponding author), Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands.	yhkhoe@protonmail.com		Khoe, Yung Han/0000-0002-1541-5490					15	1	1	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							5563	5568						6	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697206068
C	Van Hout, R; Sijs, NV; Komen, E; Van den Heuvel, H	Declerck, T	Calzolari, N; Choukri, K; Cieri, C; Hasida, K; Isahara, H; Maegaard, B; Mariani, J; Moreno, A; Odijk, J; Piperidis, S; Tokunaga, T; Goggi, S; Mazo, H		van Hout, Roeland; Van ser Sijs, Nicoline; Komen, Erwin; van den Heuvel, Henk	Declerck, T		A Fast and Flexible Webinterface for Dialect Research in the Low Countries	PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018)			English	Proceedings Paper	11th International Conference on Language Resources and Evaluation (LREC)	MAY 07-12, 2018	Miyazaki, JAPAN			web services; data curation; dialects		This paper describes the development of webportals with search applications built in order to make the data from the 33 volumes of the Dictionary of the Brabantic dialects (1967-2005) and the 39 volumes of the Dictionary of the Limburgian dialects (1983-2008) accessible and retrievable for both the research community and the general audience. Part of the data was available in a digital format, a larger part only in print. The printed data was semi-automatically converted from paper to structured text (database). This process allowed for streamlining information, applying (semi-)automatic data checks and manually correcting the input. Next, the resulting database was the backbone of a webportal for faceted search requests on the full collection, including filtering and splitting the results on metadata. The design and implementation of the webportals, called e-WBD and e-WLD, are being defined in more detail. The URLs of the portals are: http://e-wbd.nl/ and http://www.e-wld.nl/.	[van Hout, Roeland; Van ser Sijs, Nicoline; Komen, Erwin; van den Heuvel, Henk] Radboud Univ Nijmegen, CLS, Erasmuspl 1, Nijmegen, Netherlands	Radboud University Nijmegen	Van Hout, R (corresponding author), Radboud Univ Nijmegen, CLS, Erasmuspl 1, Nijmegen, Netherlands.	r.vanhout@let.ru.nl; n.vandersijs@let.ru.nl; e.komen@let.ru.nl; h.vandenheuvel@let.ru.nl			Raod voor 't Limburgs; chair of Diversity in Language and Culture of Tilburg University	Raod voor 't Limburgs; chair of Diversity in Language and Culture of Tilburg University	The data form the core of the web application. The data curation has been executed by former editor Joep Kruijsen, research assistants Linda van Meel and Aukje Borkent, student assistants Jorik van Engeland, Inge Otto, Lisette van der Heijde and Hanna van den Heuvel, interns Maaike Borst and Eline Dimmendaal. We greatly thank them for their meticulous and diligent work on the manual text processing. We also thank volunteers Jantien Kettenes-Van den Bosch and Herman Wiltink for their work on the preprocessing of the text documents. We thank the Raod voor 't Limburgs and the chair of Diversity in Language and Culture of Tilburg University for their moral and financial support, and Thijs Hermsen for drawing the website's logos showing the Limburgian and Brabantic dialect areas.		6	0	0	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-00-9				2018							3617	3621						5	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS5BI					2024-03-22	WOS:000725545003111
J	Khoe, YH; Tsoukala, C; Kootstra, GJ; Frank, SL				Khoe, Yung Han; Tsoukala, Chara; Kootstra, Gerrit Jan; Frank, Stefan L.			Is structural priming between different languages a learning effect? Modelling priming as error-driven implicit learning	LANGUAGE COGNITION AND NEUROSCIENCE			English	Article						Cross-language structural priming; error-driven implicit learning; multilingualism; sentence production; dual-path model	SHARED SYNTACTIC REPRESENTATIONS; CONNECTIONIST MODEL; R PACKAGE; BILINGUALS; PERSISTENCE; ENGLISH; INFORMATION; SPEAKING; GERMAN; ORDER	To test whether error-driven implicit learning can explain cross-language structural priming, we implemented three different models of bilingual sentence production: Spanish-English, verb-final Dutch-English, and verb-medial Dutch-English. With these models, we conducted simulation experiments that all revealed clear and strong cross-language priming effects. One of these experiments included structures with different word order between the two languages. This enabled us to distinguish between the error-driven learning account of structural priming and an alternative hybrid account which predicts that identical word order is required for cross-language priming. Cross-language priming did occur in our model between structures with different word order. This is in line with results from behavioural experiments. The results of the three experiments reveal varying degrees of evidence for stronger within-language priming than cross-language priming. This is consistent with results from behavioural studies. Overall, our findings support the viability of error-driven implicit learning as an account of cross-language structural priming.	[Khoe, Yung Han; Tsoukala, Chara; Kootstra, Gerrit Jan; Frank, Stefan L.] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Radboud University Nijmegen	Khoe, YH (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.	yunghan.khoe@ru.nl	Kootstra, Gerrit Jan/U-9128-2018	Kootstra, Gerrit Jan/0000-0002-2274-3644					62	3	3	4	20	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	2327-3798	2327-3801		LANG COGN NEUROSCI	Lang. Cogn. Neurosci.	APR 21	2023	38	4			SI		537	557		10.1080/23273798.2021.1998563	http://dx.doi.org/10.1080/23273798.2021.1998563		NOV 2021	21	Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology	F4BM9		hybrid, Green Submitted, Green Published			2024-03-22	WOS:000718782900001
C	Oostdijk, N; van Halteren, H; Basar, E; Larson, M		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		Oostdijk, Nelleke; van Halteren, Hans; Basar, Erkan; Larson, Martha			The Connection between the Text and Images of News Articles: New Insights for Multimedia Analysis	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			Corpus (Creation, Annotation etc.); Multimedia Document Processing; Tools; Systems; Applications		We report on a case study of text and images that reveals the inadequacy of simplistic assumptions about their connection and interplay. The context of our work is a larger effort to create automatic systems that can extract event information from online news articles about flooding disasters. We carry out a manual analysis of 1,000 articles containing a keyword related to flooding. The analysis reveals that the articles in our data set cluster into seven categories related to different topical aspects of flooding, and that the images accompanying the articles cluster into five categories related to the content they depict. The results demonstrate that flood-related news articles do not consistently report on a single, currently unfolding flooding event and we should also not assume that a flood-related image will directly relate to a flooding-event described in the corresponding article. In particular, spatiotemporal distance is important. We validate the manual analysis with an automatic classifier demonstrating the technical feasibility of multimedia analysis approaches that admit more realistic relationships between text and images. In sum, our case study confirms that closer attention to the connection between text and images has the potential to improve the collection of multimodal information from news articles.	[Oostdijk, Nelleke; van Halteren, Hans; Larson, Martha] Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands; [Basar, Erkan] FloodTags, The Hague, Netherlands	Radboud University Nijmegen	Oostdijk, N (corresponding author), Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands.	n.oostdijk@let.ru.nl; hvh@let.ru.nl; basar@floodtags.com; m.larson@let.ru.nl	Larson, Martha/E-9983-2014						18	2	3	1	1	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							4343	4351						9	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697205041
C	Nijveld, A; ten Bosch, L; Ernestus, M			Int Speech Commun Assoc	Nijveld, Annika; ten Bosch, Louis; Ernestus, Mirjam			ERP signal analysis with temporal resolution using a time window bank	INTERSPEECH 2019	Interspeech		English	Proceedings Paper	Interspeech Conference	SEP 15-19, 2019	Graz, AUSTRIA			EEG; ERP analyses; speech comprehension; time window analysis; linear mixed effects models	SPOKEN WORD RECOGNITION; IDENTIFICATION; SPECIFICITY	In order to study the cognitive processes underlying speech comprehension, neuro-physiological measures (e.g., EEG and MEG), or behavioural measures (e.g., reaction times and response accuracy) can be applied. Compared to behavioural measures, EEG signals can provide a more fine-grained and complementary view of the processes that take place during the unfolding of an auditory stimulus. EEG signals are often analysed after having chosen specific time windows, which are usually based on the temporal structure of ERP components expected to be sensitive to the experimental manipulation. However, as the timing of ERP components may vary between experiments, trials, and participants, such a-priori defined analysis time windows may significantly hamper the exploratory power of the analysis of components of interest. In this paper, we explore a wide-window analysis method applied to EEG signals collected in an auditory repetition priming experiment. This approach is based on a bank of temporal filters arranged along the time axis in combination with linear mixed effects modelling. Crucially, it permits a temporal decomposition of effects in a single comprehensive statistical model which captures the entire EEG trace.	[Nijveld, Annika; ten Bosch, Louis; Ernestus, Mirjam] Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands; [ten Bosch, Louis] Radboud Univ Nijmegen, CLST, Nijmegen, Netherlands; [ten Bosch, Louis] Donders Inst, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Nijveld, A (corresponding author), Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands.	a.nijveld@let.ru.nl; l.tenbosch@let.ru.nl; m.ernestus@let.ru.nl	Ernestus, Mirjam/E-4344-2010	ten bosch, louis/0000-0002-0152-9024					15	2	2	1	1	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2019							1208	1212		10.21437/Interspeech.2019-2729	http://dx.doi.org/10.21437/Interspeech.2019-2729			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4LP		Green Published			2024-03-22	WOS:000831796401073
C	Sanders, E; van den Bosch, A		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		Sanders, Eric; van den Bosch, Antal			Optimising Twitter-based Political Election Prediction with Relevance and Sentiment Filters	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			Large Scale Annotation; Election Prediction; Relevance Filters; Sentiment Analysis		We study the relation between the number of mentions of political parties in the last weeks before the elections and the election results. In this paper we focus on the Dutch elections of the parliament in 2012 and for the provinces (and the senate) in 2011 and 2015. With raw counts, without adaptations, we achieve a mean absolute error (MAE) of 2.71% for 2011, 2.02% for 2012 and 2.89% for 2015. A set of over 17,000 tweets containing political party names were annotated by at least three annotators per tweet on ten features denoting communicative intent (including the presence of sarcasm, the message's polarity, the presence of an explicit voting endorsement or explicit voting advice, etc.). The annotations were used to create oracle (gold-standard) filters. Tweets with or without a certain majority annotation are held out from the tweet counts, with the goal of attaining lower MAEs. With a grid search we tested all combinations of filters and their responding MAE to find the best filter ensemble. It appeared that the filters show markedly different behaviour for the three elections and only a small MAE improvement is possible when optimizing on all three elections. Larger improvements for one election are possible, but result in deterioration of the MAE for the other elections.	[Sanders, Eric] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; KNAW Meertens Inst, Amsterdam, Netherlands	Radboud University Nijmegen; Royal Netherlands Academy of Arts & Sciences; Meertens Institute (KNAW)	Sanders, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	e.sanders@let.ru.nl; antal.van.den.bosch@meertens.knaw.nl		van den Bosch, Antal/0000-0003-2493-656X					8	2	2	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							6158	6165						8	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697207021
C	Sanders, E; van den Bosch, A		Weber, I; Darwish, KM; Wagner, C; Zagheni, E; Nelson, L; Aref, S; Flock, F		Sanders, Eric; van den Bosch, Antal			A Longitudinal Study on Twitter-Based Forecasting of Five Dutch National Elections	SOCIAL INFORMATICS, SOCINFO 2019	Lecture Notes in Computer Science		English	Proceedings Paper	11th Conference on Social Informatics (SocInfo)	NOV 18-21, 2019	Doha, QATAR	Qatar Natl Res Fund, Qatar Comp Res Inst, NW Univ, Carnegie Mellon Univ, Springer		Twitter; Election forecasting; Longitudinal study	PREDICTING ELECTIONS	We report on an eight-year longitudinal study of predicting the outcome of elections based on party mentions in tweets. Five Dutch national elections for the parliament and senate between 2011 and 2019 were examined. Configurations with four parameters were tested. For three elections, reasonably accurate predictions can be obtained that are under twice the error of the classic polls, but only after post-hoc optimization. When the same optimal parameter configuration is used for all elections, the results worsen.	[Sanders, Eric; van den Bosch, Antal] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [van den Bosch, Antal] KNAW Meertens Inst, Amsterdam, Netherlands	Radboud University Nijmegen; Royal Netherlands Academy of Arts & Sciences; Meertens Institute (KNAW)	Sanders, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	e.sanders@let.ru.nl; antal.van.den.bosch@meertens.knaw.nl		van den Bosch, Antal/0000-0003-2493-656X					21	2	2	0	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-030-34971-4; 978-3-030-34970-7	LECT NOTES COMPUT SC			2019	11864						128	142		10.1007/978-3-030-34971-4_9	http://dx.doi.org/10.1007/978-3-030-34971-4_9			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BQ6FJ					2024-03-22	WOS:000611501800009
J	Rafiee, A; Spooren, W; Sanders, J				Rafiee, Afrooz; Spooren, Wilbert; Sanders, Jose			Culture and discourse structure: A comparative study of Dutch and Iranian news texts	DISCOURSE & COMMUNICATION			English	Article						Chronology; discourse analysis; hybrid news; Iranian news; news structure	NEWSPAPER EDITORIALS; JOURNALISM; ENGLISH; RETHINKING	Many studies of structure in present-day Western news texts have shown that the dominant structure is the inverted pyramid, even if the use of a chronological narrative structure is acknowledged. However, the relevant literature has exclusively investigated Western news texts. In this study, we challenge the dominance of the inverted news structure by including a non-Western and less-investigated culture and ask whether textual structure of news texts can differ between cultural contexts. In total, 100 crime news texts from national Iranian and Dutch newspapers were analyzed for both the overall text and the journalists' statements. Those texts that showed a hybrid structure (combining inverted pyramid and chronology) were subsequently studied qualitatively to understand how chronology is applied in them. News texts from the two cultures were significantly different in their structure. Qualitative analysis of the journalistic statements uncovered a quotation-based structure, a way of news writing in Iranian journalistic statements in which the journalist mainly narrates reporting eventualities that are new to Western eyes. The study offers implications for further ethnography of news and communication, suggesting that the role, pattern and effects of (journalistic) communication can be culture-specific.	[Rafiee, Afrooz] Radboud Univ Nijmegen, POB 9103, NL-6500 HD Nijmegen, Netherlands; [Spooren, Wilbert] Radboud Univ Nijmegen, CLS, Discourse Studies Dutch, Nijmegen, Netherlands; [Sanders, Jose] Radboud Univ Nijmegen, CLS, Narrat Commun, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Rafiee, A (corresponding author), Radboud Univ Nijmegen, POB 9103, NL-6500 HD Nijmegen, Netherlands.	a.rafiee@let.ru.nl							71	7	7	3	19	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1750-4813	1750-4821		DISCOURSE COMMUN	Discourse Commun.	FEB	2018	12	1					58	79		10.1177/1750481317735626	http://dx.doi.org/10.1177/1750481317735626			22	Communication	Social Science Citation Index (SSCI)	Communication	FS5PP		Bronze			2024-03-22	WOS:000419850500004
C	van den Heuvel, H; Komen, E; Oostdijk, N	Declerck, T	Calzolari, N; Choukri, K; Cieri, C; Hasida, K; Isahara, H; Maegaard, B; Mariani, J; Moreno, A; Odijk, J; Piperidis, S; Tokunaga, T; Goggi, S; Mazo, H		van den Heuvel, Henk; Komen, Erwin; Oostdijk, Nelleke	Declerck, T		Metadata Collection Records for Language Resources	PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018)			English	Proceedings Paper	11th International Conference on Language Resources and Evaluation (LREC)	MAY 07-12, 2018	Miyazaki, JAPAN			LR infrastructure; metadata; collection records; Collection Bank		In this paper we motivate the need for introducing more elaborate and consistent metadata records for collections of (linguistic) data resources in the CLARIN context. For this purpose we designed and implemented a CMDI profile. We validated the profile in a first pilot in which we populated the profile for 45 Dutch language resources. Given the complexity of the profile and special purpose requirements we developed our own interface for creating, editing, listing, copying and exporting descriptions of metadata collection records. The requirements for this interface and its implementation are described.	[van den Heuvel, Henk; Oostdijk, Nelleke] Radboud Univ Nijmegen, CLST, CLS, Erasmuspl 1, Nijmegen, Netherlands; [van den Heuvel, Henk; Komen, Erwin] Radboud Univ Nijmegen, Humanities Lab, Erasmuspl 1, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Van den Heuvel, H (corresponding author), Radboud Univ Nijmegen, CLST, CLS, Erasmuspl 1, Nijmegen, Netherlands.; Van den Heuvel, H (corresponding author), Radboud Univ Nijmegen, Humanities Lab, Erasmuspl 1, Nijmegen, Netherlands.	h.vandenheuvel@let.ru.nl; e.komen@let.ru.nl; n.oostdijk@let.ru.nl			Dutch CLARIAH programmme [CC-WP3-15-002]	Dutch CLARIAH programmme	The work reported here was funded by the Dutch CLARIAH programmme<SUP>26</SUP> under project number CC-WP3-15-002. We are grateful to Hanna van den Heuvel for editing the metadata collection records in the project.		12	0	0	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-00-9				2018							1282	1288						7	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS5BI					2024-03-22	WOS:000725545001057
C	Nallanthighal, VS; Härmä, A; Strik, H			IEEE	Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer			SPEECH BREATHING ESTIMATION USING DEEP LEARNING METHODS	2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 04-08, 2020	Barcelona, SPAIN	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers, Signal Proc Soc		Speech breathing; signal processing; speech technology; deep neural networks; Multi task learning	RIB CAGE	Breathing is the primary mechanism for maintaining the sub-glottal pressure for speech production. Speech can be seen as a systematic outflow of air during exhalation characterized by linguistic content and prosodic factors. Thus, sensing respiratory dynamics from the speech is plausible. In this paper, we explore techniques for sensing breathing from speech using deep learning architectures including multi-task learning approaches. Estimating the breathing pattern from the speech would give us information about the respiration rate, breathing capacity and thus enable us to understand the pathological condition of a person using one's speech. Training and evaluation of our model on our database of breathing signal and speech for 40 subjects yielded a sensitivity of 0.88 for breath event detection and 5.6 % error for breathing rate estimation.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, VS (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.			Harma, Aki/0000-0002-2966-3305	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science Department, Philips Research, Eindhoven	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project; Data Science Department, Philips Research, Eindhoven	This work was partially supported by the Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science Department, Philips Research, Eindhoven.		16	14	14	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-5090-6631-5	INT CONF ACOUST SPEE			2020							1140	1144		10.1109/icassp40776.2020.9053753	http://dx.doi.org/10.1109/icassp40776.2020.9053753			5	Acoustics; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Engineering	BQ7HU					2024-03-22	WOS:000615970401076
C	Nallanthighal, VS; Härmä, A; Strik, H			IEEE	Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer			DETECTION OF COPD EXACERBATION FROM SPEECH: COMPARISON OF ACOUSTIC FEATURES AND DEEP LEARNING BASED SPEECH BREATHING MODELS	2022 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	47th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 22-27, 2022	Singapore, SINGAPORE	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		COPD exacerbation; speech technology; statistical approach; deep neural networks; speech breathing	SIGNAL	Respiration is a primary process involved in speech production. We can often hear if a person has respiratory difficulty, thus making speech a good pathological indicator for respiratory conditions. This is more relevant to conditions like chronic obstructive pulmonary disease (COPD). Patients with COPD suffer from voice changes with respect to the healthy population. Medical professionals observe that the speech of COPD patients during stable periods differs from the speech during exacerbation. In this paper, we investigate this detection of COPD exacerbation from speech in three approaches: acoustic features identification using a statistical approach, low-level descriptive features with classification, and speech breathing models based on deep learning architectures to estimate the patients' breathing rate. Our analysis indicates that each of these approaches indeed results in a clear distinction of speech during exacerbation and stable periods of COPD.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, VS (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.			Harma, Aki/0000-0002-2966-3305	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science Department, Philips Research, Eindhoven	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project; Data Science Department, Philips Research, Eindhoven	This work was partially supported by the Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science Department, Philips Research, Eindhoven.		19	2	2	1	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-6654-0540-9	INT CONF ACOUST SPEE			2022							9097	9101		10.1109/ICASSP43922.2022.9747785	http://dx.doi.org/10.1109/ICASSP43922.2022.9747785			5	Acoustics; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Engineering	BT9UB					2024-03-22	WOS:000864187909082
C	Nallanthighal, VS; Härmä, A; Strik, H			Int Speech Commun Assoc	Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer			Deep sensing of breathing signal during conversational speech	INTERSPEECH 2019	Interspeech		English	Proceedings Paper	Interspeech Conference	SEP 15-19, 2019	Graz, AUSTRIA			breathing detection; pathological speech; speech technology; deep neural networks; respiratory diseases	VOLUME	In this paper, we show the first results on the estimation of breathing signal from conversational speech using deep learning algorithms. Respiratory diseases such as COPD, asthma, and respiratory infections are common in the elderly population and patients in health care monitoring and medical alert services in general. In this work, we compare algorithms for the estimation of a known respiratory target signal, measured by respiratory belt transducers positioned across the rib cage and abdomen, from conversational speech. We demonstrate the estimation of the respiratory signal from speech using convolutional and recurrent neural networks. The estimated breathing pattern gives respiratory rate, breathing capacity and thus might provide indications of the pathological condition of the speaker. Evaluation of our model on our database of breathing signal and speech yielded a sensitivity of 91.2 % for breath event detection and a mean absolute error of 1.01 breaths per minute for breathing rate estimation.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, VS (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.	srikanth.nallanthighal@philips.com; aki.harma@philips.com; w.strik@let.ru.nl		Harma, Aki/0000-0002-2966-3305; Strik, Helmer/0000-0003-1722-3465	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science Department, Philips Research, Eindhoven	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project; Data Science Department, Philips Research, Eindhoven	This work was partially supported by the Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science Department, Philips Research, Eindhoven.		17	24	24	0	2	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2019							4110	4114		10.21437/Interspeech.2019-1796	http://dx.doi.org/10.21437/Interspeech.2019-1796			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4LP		Green Published			2024-03-22	WOS:000831796404051
C	van den Heuvel, H; Oostdijk, N; Rowland, C; Trilsbeek, P		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		van den Heuvel, Henk; Oostdijk, Nelleke; Rowland, Caroline; Trilsbeek, Paul			The CLARIN Knowledge Centre for Atypical Communication Expertise	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			infrastructure; atypical communication; language resources		This paper introduces a new CLARIN Knowledge Center which is the K-Centre for Atypical Communication Expertise (ACE for short) which has been established at the Centre for Language and Speech Technology (CLST) at Radboud University. Atypical communication is an umbrella term used here to denote language use by second language learners, people with language disorders or those suffering from language disabilities, but also more broadly by bilinguals and users of sign languages. It involves multiple modalities (text, speech, sign, gesture) and encompasses different developmental stages. ACE closely collaborates with The Language Archive (TLA) at the Max Planck Institute for Psycholinguistics in order to safeguard GDPR-compliant data storage and access. We explain the mission of ACE and show its potential on a number of showcases and a use case.	[van den Heuvel, Henk; Oostdijk, Nelleke] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Rowland, Caroline; Trilsbeek, Paul] MPI Psycholinguist, Language Arch, Nijmegen, Netherlands; [Rowland, Caroline] Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Max Planck Society; Radboud University Nijmegen	Van den Heuvel, H (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	h.vandenheuvel@let.ru.nl; n.oostdijk@let.ru.nl; caroline.rowland@mpi.nl; paul.trilsbeek@mpi.nl	Trilsbeek, Paul/H-9883-2016	van den Heuvel, Henk/0000-0003-2064-0630					21	5	6	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							3312	3316						5	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697204037
C	Nallanthighal, VS; Harma, A; Strik, H			Int Speech Commun Assoc	Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer			COVID-19 detection based on respiratory sensing from speech	INTERSPEECH 2022	Interspeech		English	Proceedings Paper	Interspeech Conference	SEP 18-22, 2022	Incheon, SOUTH KOREA			COVID-19; respiratory sensing; pathological speech; speech technology; deep neural networks	RIB CAGE	COVID-19 affects a person's respiratory health, which is manifested in the form of shortness of breath during speech. Recent work shows that it is possible to use deep learning techniques to sense the speaker's respiratory parameters from a speech signal directly. Thus respiratory parameters like speech breathing rate and tidal volume can be computed and compared using deep learning techniques to detect COVID-19 from speech recordings. In this paper, we compute respiratory parameters using our pre-trained deep learning-based speech breathing models and use them for detecting COVID-19 from speech. Apart from using speech breathing models, we perform acoustic features identification using a statistical approach and classification based on low-level descriptive features. Our analysis investigates the distinction of speech of a healthy person and COVID-19 affected person.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, VS (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.	srikanth.nallanthighal@philips.com; aki.harma@philips.com; w.strik@let.ru.nl		Harma, Aki/0000-0002-2966-3305	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science department, Philips Research, Eindhoven	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project; Data Science department, Philips Research, Eindhoven	This work was partially supported by the Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science department, Philips Research, Eindhoven.		25	1	1	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2022							2498	2502		10.21437/Interspeech.2022-11209	http://dx.doi.org/10.21437/Interspeech.2022-11209			5	Acoustics; Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Audiology & Speech-Language Pathology; Computer Science; Engineering	BU4IZ		Green Published			2024-03-22	WOS:000900724502135
C	Nallanthighal, V; Harm, A; Rietman, R; Strik, H		Bier, N; Fred, A; Gamboa, H		Nallanthighal, Venkata; Harm, Aki; Rietman, Ronald; Strik, Helmer			Detection of Coughing and Respiratory Sensing in Conversational Speech	HEALTHINF: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 5: HEALTHINF			English	Proceedings Paper	15th International Conference on Health Informatics (HEALTHINF) held as part of 15th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC)	FEB 09-11, 2022	ELECTR NETWORK	INSTICC		Speech Breathing; Signal Processing; Deep Neural Networks; Respiratory Parameters; Speech Technology	NEURAL-NETWORKS; RIB CAGE	Coughing and shortness of breath are typical symptoms in people suffering from COPD, asthma, and COVID-19 conditions. Separate studies have shown that coughing and respiratory health parameters, respectively, can be sensed from a conversational speech recording using deep learning techniques. This paper looks into joint sensing of coughing events and the breathing pattern during natural speech. We introduce an algorithm and demonstrate its performance in realistic recordings. We observed sensitivity of 92.4% and 91.6% for cough detection and breath event detection, respectively.	[Nallanthighal, Venkata; Harm, Aki; Rietman, Ronald] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, V (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, V (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.				Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science Department, Philips Research, Eindhoven	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project; Data Science Department, Philips Research, Eindhoven	This work was partially supported by the Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science Department, Philips Research, Eindhoven.		22	0	0	0	1	SCITEPRESS	SETUBAL	AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL			978-989-758-552-4				2021							289	295		10.5220/0010709700003123	http://dx.doi.org/10.5220/0010709700003123			7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Medical Informatics	BS9AB		hybrid			2024-03-22	WOS:000778794900027
C	Tejedor-García, C; van der Molen, B; van den Heuvel, H; van Hessen, A; Pieters, T	Mariani, J	Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mazo, H; Odijk, H; Piperidis, S		Tejedor-Garcia, Cristian; van der Molen, Berrie; van den Heuvel, Henk; van Hessen, Arjan; Pieters, Toine	Mariani, J		Towards an Open-Source Dutch Speech Recognition System for the Healthcare Domain	LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION			English	Proceedings Paper	13th International Conference on Language Resources and Evaluation (LREC)	JUN 20-25, 2022	Marseille, FRANCE	Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur		speech recognition; language modeling; domain adaptation; healthcare	TECHNOLOGY; VOICE	The current largest open-source generic automatic speech recognition (ASR) system for Dutch, Kaldi NL, does not include a domain-specific healthcare jargon in the lexicon. Commercial alternatives (e.g., Google ASR system) are also not suitable for this purpose, not only because of the lexicon issue, but they do not safeguard privacy of sensitive data sufficiently and reliably. These reasons motivate that just a small amount of medical staff employs speech technology in the Netherlands. This paper proposes an innovative ASR training method developed within the Homo Medicinalis (HoMed) project. On the semantic level it specifically targets automatic transcription of doctor-patient consultation recordings with a focus on the use of medicines. In the first stage of HoMed, the Kaldi NL language model (LM) is fine-tuned with lists of Dutch medical terms and transcriptions of Dutch online healthcare news bulletins. Despite the acoustic challenges and linguistic complexity of the domain, we reduced the word error rate (WER) by 5.2%. The proposed method could be employed for ASR domain adaptation to other domains with sensitive and special category data. These promising results allow us to apply this methodology on highly sensitive audiovisual recordings of patient consultations at the Netherlands Institute for Health Services Research (Nivel).	[Tejedor-Garcia, Cristian; van den Heuvel, Henk] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [van der Molen, Berrie; Pieters, Toine] Univ Utrecht, Freudenthal Inst, Utrecht, Netherlands; [van Hessen, Arjan] Univ Twente, HMI, Enschede, Netherlands	Radboud University Nijmegen; Utrecht University; University of Twente	Tejedor-García, C (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	cristian.tejedorgarcia@ru.nl; b.j.vandermolen@uu.nl; henk.vandenheuvel@RU.NL; a.j.vanhessen@utwente.nl; t.pieters@uu.nl	Pieters, Toine/JUV-5802-2023; Tejedor-García, Cristian/AAP-2048-2021	Tejedor-García, Cristian/0000-0001-5395-0438	Platform Digitale Infrastructuur Social Science and Humanities (PDI-SSH)	Platform Digitale Infrastructuur Social Science and Humanities (PDI-SSH)	The research funding for this study was supported by the Platform Digitale Infrastructuur Social Science and Humanities (PDI-SSH) 2020 (https://pdi-ssh.nl/). The authors would also like to thank Sandra van Dulmen for her valuable feedback.		40	1	1	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-72-6				2022							1032	1039						8	Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BU2ZO					2024-03-22	WOS:000889371701014
C	Nallanthighal, VS; Härmä, A; Strik, H; Doss, MM			EURASIP	Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer; Doss, Mathew Magimai			PHONEME BASED RESPIRATORY ANALYSIS OF READ SPEECH	29TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO 2021)	European Signal Processing Conference		English	Proceedings Paper	29th European Signal Processing Conference (EUSIPCO)	AUG 23-27, 2021	ELECTR NETWORK	European Assoc Signal Proc		breathing signal; phonetics; Respiratory effort; speech technology; signal processing	AIR-FLOW	Recent work shows that it is possible to use deep learning techniques to sense the speaker's respiratory parameters directly from a speech signal. This can be a beneficial option for future telehealth services. In this paper, we dive deeper and study how respiratory effort depends on the linguistic content of the speech utterance. This is obtained by analysis of respiratory belt sensor data and phoneme-aligned speech data. The results show, for example, that the respiratory effort was highest for fricatives, compared to other broad phonetic classes, and especially high for the glottal consonants. The insights may help to develop more efficient protocols for respiratory health monitoring in telehealth applications.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Doss, Mathew Magimai] Idiap Res Inst, Martigny, Switzerland	Philips; Philips Research; Radboud University Nijmegen	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.; Nallanthighal, VS (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.			Magimai Doss, Mathew/0000-0002-8714-1409; Harma, Aki/0000-0002-2966-3305	EU's H2020 Marie Sklodowska-Curie programme TAPAS [766287]	EU's H2020 Marie Sklodowska-Curie programme TAPAS	This work is supported under the EU's H2020 Marie Sklodowska-Curie programme TAPAS; Grant No: 766287. The authors would like to thank Qingran Zhan, IDIAP Research institute for the help with phoneme alignment.		19	1	1	0	1	EUROPEAN ASSOC SIGNAL SPEECH & IMAGE PROCESSING-EURASIP	KESSARIANI	PO BOX 74251, KESSARIANI, 151 10, GREECE	2076-1465		978-9-0827-9706-0	EUR SIGNAL PR CONF			2021							191	195						5	Acoustics; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology; Telecommunications	BS7MG					2024-03-22	WOS:000764066600039
C	Yilmaz, E; van den Heuvel, H; van Leeuwen, DA			Int Speech Commun Assoc	Yilmaz, Emre; van den Heuvel, Henk; van Leeuwen, David A.			Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech	19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES	Interspeech		English	Proceedings Paper	19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018)	AUG 02-SEP 06, 2018	Hyderabad, INDIA	Int Speech Commun Assoc		code-switching; bilingual ASR; under-resourced languages; Frisian language	MODEL	In this paper, we describe several techniques for improving the acoustic and language model of an automatic speech recognition (ASR) system operating on code-switching (CS) speech. We focus on the recognition of Frisian-Dutch radio broadcasts where one of the mixed languages, namely Frisian, is an underresourced language. In previous work, we have proposed several automatic transcription strategies for CS speech to increase the amount of available training speech data. In this work, we explore how the acoustic modeling (AM) can benefit from monolingual speech data belonging to the high-resourced mixed language. For this purpose, we train state-of-the-art AMs, which were ineffective due to lack of training data, on a significantly increased amount of CS speech and monolingual Dutch speech. Moreover, we improve the language model (LM) by creating code-switching text, which is in practice almost nonexistent, by (1) generating text using recurrent LMs trained on the transcriptions of the training CS speech data, (2) adding the transcriptions of the automatically transcribed CS speech data and (3) translating Dutch text extracted from the transcriptions of a large Dutch speech corpora. 'We report significantly improved CS ASR performance due to the increase in the acoustic and textual training data.	[Yilmaz, Emre; van den Heuvel, Henk; van Leeuwen, David A.] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Yilmaz, Emre] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore	Radboud University Nijmegen; National University of Singapore	Yilmaz, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.; Yilmaz, E (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.	e.yilmaz@let.ru.nl; h.vandenheuvel@let.ru.nl; d.vanleeuwen@let.ru.nl	YILMAZ, EMRE/K-4777-2016	YILMAZ, EMRE/0000-0001-7466-3358; van den Heuvel, Henk/0000-0003-2064-0630	NWO Project [314-99-119]	NWO Project	This research is funded by the NWO Project 314-99-119 (Frisian Audio Mining Enterprise).		40	23	25	0	1	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X		978-1-5108-7221-9	INTERSPEECH			2018							1933	1937						5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BM5PH					2024-03-22	WOS:000465363900404
C	Bentum, M; ten Bosch, L; van den Heuvel, H; Wills, S; van der Niet, D; Dijkstra, J; Van de Velde, H	Mariani, J	Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mazo, H; Odijk, H; Piperidis, S		Bentum, Martijn; ten Bosch, Louis; van den Heuvel, Henk; Wills, Simone; van der Niet, Domenique; Dijkstra, Jelske; Van de Velde, Hans	Mariani, J		A Speech Recognizer for Frisian/Dutch Council Meetings	LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION			English	Proceedings Paper	13th International Conference on Language Resources and Evaluation (LREC)	JUN 20-25, 2022	Marseille, FRANCE	Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur		ASR; Code Switching; Frisian; Dutch; Domain Adaptation		We developed a bilingual Frisian/Dutch speech recognizer for council meetings in Fryslan (the Netherlands). During these meetings both Frisian and Dutch are spoken, and code switching between both languages shows up frequently. The new speech recognizer is based on an existing speech recognizer for Frisian and Dutch named FAME!, which was trained and tested on historical radio broadcasts. Adapting a speech recognizer for the council meeting domain is challenging because of acoustic background noise, speaker overlap and the jargon typically used in council meetings. To train the new recognizer, we used the radio broadcast materials utilized for the development of the FAME! recognizer and added newly created manually transcribed audio recordings of council meetings from eleven Frisian municipalities, the Frisian provincial council and the Frisian water board. The council meeting recordings consist of 49 hours of speech, with 26 hours of Frisian speech and 23 hours of Dutch speech. Furthermore, from the same sources, we obtained texts in the domain of council meetings containing 11 million words; 1.1 million Frisian words and 9.9 million Dutch words. We describe the methods used to train the new recognizer, report the observed word error rates, and perform an error analysis on remaining errors.	[Bentum, Martijn; ten Bosch, Louis; van den Heuvel, Henk; Wills, Simone] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [van der Niet, Domenique] Humainr, Leeuwarden, Netherlands; [Dijkstra, Jelske; Van de Velde, Hans] Fryske Akad, Leeuwarden, Netherlands; [Van de Velde, Hans] Univ Utrecht, Utrecht, Netherlands	Radboud University Nijmegen; Royal Netherlands Academy of Arts & Sciences; Fryske Akademy (FA-KNAW); Utrecht University	Bentum, M (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	martijn.bentum@ru.nl; louis.tenbosch@ru.nl; henk.vandenheuvel@ru.nl; simone.wills@ru.nl; domenique@humainr.com; jdijkstra@fryske-akademy.nl; hvandevelde@fryske-akademy.nl	Van de Velde, Hans/K-5575-2015	Van de Velde, Hans/0000-0003-2197-5555	Provinsje Fryslan; Wetterskip Fryslan; Fryske Akademy; Humain'r	Provinsje Fryslan; Wetterskip Fryslan; Fryske Akademy; Humain'r	The development of the speech recognizer was financed and executed by Provinsje Fryslan, Wetterskip Fryslan and the municipalities Achtkarspelen, Dantumadiel, Fryske Marren, Heerenveen, Leeuwarden, Noardeast-Fryslan, Opsterland, Smallingerland, Sudwest-Fryslan, Tytsjerksteradiel and Waadhoeke.; The development of the multilingual and multidialect transcription software was financed and executed by Fryske Akademy and Humain'r.; The development of the training program for Frisian/Dutch transcriptions for training ASR systems was financed and executed by Fryske Akademy and Humain'r.		13	0	0	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-72-6				2022							1009	1015						7	Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BU2ZO					2024-03-22	WOS:000889371701011
J	Hinskens, F				Hinskens, Frans			Variation in R-Pronouns in Moroccan and Turkish Ethnolectal Dutch and What It Tells Us	LANGUAGES			English	Article						R-words; R-pronouns; prepositional phrases; ethnolects; language contact; language variation; internal conditioning; social conditioning	EMERGENCE; LANGUAGE	R-pronouns are R-words which feature as pronouns in prepositional phrases (among other things). They are common in Dutch and German (e.g., D. daarmee, G. damit, lit. 'therewith', 'with that', D. erna, G. danach, lit. 'hereafter', 'after this'). This contribution concerns a quantitative study of variation in R-pronouns in modern Moroccan and Turkish ethnolectal Dutch. In conversational speech of bilingual speakers of Moroccan Dutch, Turkish Dutch and two groups of monolingual 'white' Dutch (one of them being the control group), R-pronouns appear to vary in three dimensions: the R-pronoun can or cannot be realized (with the latter option violating the norms of Dutch); if it is realized, the R-pronoun and the preposition can or cannot be split (both options conform the norms of Standard Dutch), if the R-pronoun is not realized, then either another pronoun is used instead or there is no substitute (both variants violate the norms of Dutch). For all three dimensions of variation, statistical analyses were carried out, starting from a total of 1160 realizations by 52 representatives of the four groups. The analyses involved three internal parameters and four social ones. The results serve to answer research questions concerning the origin of the variation, its place in the verbal repertoires and the social spread of the variation.	[Hinskens, Frans] Meertens Inst KNAW, NL-1001 EW Amsterdam, Netherlands; [Hinskens, Frans] Radboud Univ Nijmegen, Ctr Language Studies CLS, NL-6500 HD Nijmegen, Netherlands	Royal Netherlands Academy of Arts & Sciences; Meertens Institute (KNAW); Radboud University Nijmegen	Hinskens, F (corresponding author), Meertens Inst KNAW, NL-1001 EW Amsterdam, Netherlands.; Hinskens, F (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, NL-6500 HD Nijmegen, Netherlands.	frans.hinskens@meertens.knaw.nl		Hinskens, Frans/0000-0002-0572-154X	Netherlands Organization for Scientific Research (NWO); Meertens Instituut and Radboud Universiteit, Nijmegen;  [254-70-040]	Netherlands Organization for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO)); Meertens Instituut and Radboud Universiteit, Nijmegen; 	This research was funded in 2005-15 by the Netherlands Organization for Scientific Research (NWO; project number 254-70-040), the Meertens Instituut and Radboud Universiteit, Nijmegen.		36	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2226-471X		LANGUAGES-BASEL	Languages-Basel	DEC	2022	7	4							259	10.3390/languages7040259	http://dx.doi.org/10.3390/languages7040259			25	Linguistics; Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	7E0SX		gold, Green Published			2024-03-22	WOS:000900890500001
J	Xue, W; Cucchiarini, C; van Hout, R; Strik, H				Xue, Wei; Cucchiarini, Catia; van Hout, Roeland; Strik, Helmer			Measuring the intelligibility of dysarthric speech through automatic speech recognition in a pluricentric language	SPEECH COMMUNICATION			English	Article						Pluricentric language; Speech intelligibility; Automatic speech recognition; Dysarthric speech		Speech intelligibility is an essential though complex construct for evaluating dysarthric speech. Various pro-cedures can be used to measure speech intelligibility, most of which are based on subjective ratings assigned by experts. Since these procedures are subjective and laborious, automatic speech recognition (ASR) has been proposed to obtain objective metrics of intelligibility. Although promising results have been reported, ASR for dysarthric speech generally requires large amounts of data consisting of recorded and annotated speech. In the present study, we explored the possibility of using dysarthric speech resources from the dominant language variety to improve the performance of ASR systems on the dysarthric speech of the non-dominant variety of the same pluricentric language. Dutch is used as an example of a pluricentric language, with Netherlandic Dutch considered the dominant and Flemish Dutch the non-dominant variety. The performance of ASR is evaluated by using two types of intelligibility metrics: orthographic transcriptions and global intelligibility assessments, both obtained from experts. Overall, the results show that dysarthric speech data from the dominant language variety can contribute to improving automatic transcriptions and to developing objective, automatic global measures of speech intelligibility only when no data from the non-dominant variety are available for training ASR models.	[Xue, Wei; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [Xue, Wei; Cucchiarini, Catia; van Hout, Roeland; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, Helmer] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.; Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands.	wei.xue@ru.nl		Xue, Wei/0000-0001-9498-3519	European Union?s Horizon 2020 research and innovation program [766287]	European Union?s Horizon 2020 research and innovation program(Horizon 2020)	This work was supported by the European Union's Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant agreement [grant number 766287].		36	2	2	2	6	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	MAR	2023	148						23	30		10.1016/j.specom.2023.02.004	http://dx.doi.org/10.1016/j.specom.2023.02.004		FEB 2023	8	Acoustics; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Acoustics; Computer Science	9W0BT		Green Published, hybrid			2024-03-22	WOS:000948748400001
J	Xue, W; van Hout, R; Cucchiarini, C; Strik, H				Xue, Wei; van Hout, Roeland; Cucchiarini, Catia; Strik, Helmer			Assessing speech intelligibility of pathological speech: test types, ratings and transcription measures	CLINICAL LINGUISTICS & PHONETICS			English	Article						Speech intelligibility; dysarthric speech; Visual Analogue Scale; orthographic transcription; interrater reliability; construct and concurrent validity	GENERALIZABILITY THEORY; SENTENCE INTELLIGIBILITY; DYSARTHRIC SPEAKERS; PARKINSONS-DISEASE; MULTIPLE-SCLEROSIS; SCORES; FAMILIARIZATION; RELIABILITY; ADULTS	Speech intelligibility is an essential though complex construct in speech pathology. In this paper, we investigated the interrater reliability and validity of two types of intelligibility measures: a rating-based measure, through Visual Analogue Scales (VAS), and a transcription-based measure called Accuracy of Words (AcW), through two forms of orthographic transcriptions, one containing only existing words (EWTrans) and one allowing all sorts of words, including both existing words and pseudowords (AWTrans). Both VAS and AcW scores were collected from five expert raters. We selected speakers with various severity levels of dysarthria (SevL) and employed two types of speech materials, i.e. meaningful sentences and word lists. To measure reliability, we applied Generalizability Theory, which is relatively unknown in the field of pathological speech and language research but enables more comprehensive analyses than traditional methods, e.g., the intraclass correlation coefficient. The results convincingly indicate that five expert raters were sufficient to provide reliable rating-based (VAS) and transcription-based (AcW) measures, and that reliability increased as the number of raters or utterances increased. Generalizability Theory has proved effective in systematically dealing with reliability issues in our experimental design. We also investigated construct and concurrent validity. Construct validity was addressed by exploring the correlations between VAS and AcW within and across speech materials. Concurrent validity was addressed by exploring the correlations between our measures, i.e. VAS and AcW, and two external measures, i.e. phoneme intelligibility and SevL. The correlations corroborate the validity of VAS and AcW to assess speech intelligibility, both in sentences and word lists.	[Xue, Wei; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [van Hout, Roeland; Cucchiarini, Catia; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	wei.xue@ru.nl			European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Grant [766287]	European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Grant(Marie Curie Actions)	This work was supported by the European Union's Horizon 2020 research and innovation pro-gramme under the Marie Sklodowska-Curie Grant number [766287].		69	4	5	1	1	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0269-9206	1464-5076		CLIN LINGUIST PHONET	Clin. Linguist. Phon.	JAN 2	2023	37	1					52	76		10.1080/02699206.2021.2009918	http://dx.doi.org/10.1080/02699206.2021.2009918		DEC 2021	25	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	7K7KI	34955083	Green Published, hybrid			2024-03-22	WOS:000734811600001
J	Yilmaz, E; McLaren, M; van den Heuvel, H; van Leeuwen, DA				Yilmaz, Emre; McLaren, Mitchell; van den Heuvel, Henk; van Leeuwen, David A.			Semi-supervised acoustic model training for speech with code-switching	SPEECH COMMUNICATION			English	Article						Automatic speech recognition; Code-switching; Speaker and language recognition; Bilingual acoustic modeling; Semi-supervised training; Frisian language	SPEAKER DIARIZATION; KNOWLEDGE TRANSFER; RECOGNITION; TRANSCRIPTION; FEATURES; CORPUS	In the FAME! project, we aim to develop an automatic speech recognition (ASR) system for Frisian-Dutch code-switching (CS) speech extracted from the archives of a local broadcaster with the ultimate goal of building a spoken document retrieval system. Unlike Dutch, Frisian is a low-resourced language with a very limited amount of manually annotated speech data. In this paper, we describe several automatic annotation approaches to enable using of a large amount of raw bilingual broadcast data for acoustic model training in a semi-supervised setting. Previously, it has been shown that the best-performing ASR system is obtained by two-stage multilingual deep neural network (DNN) training using 11 hours of manually annotated CS speech (reference) data together with speech data from other high-resourced languages. We compare the quality of transcriptions provided by this bilingual ASR system with several other approaches that use a language recognition system for assigning language labels to raw speech segments at the front-end and using monolingual ASR resources for transcription. We further investigate automatic annotation of the speakers appearing in the raw broadcast data by first labeling with (pseudo) speaker tags using a speaker diarization system and then linking to the known speakers appearing in the reference data using a speaker recognition system. These speaker labels are essential for speaker-adaptive training in the proposed setting. We train acoustic models using the manually and automatically annotated data and run recognition experiments on the development and test data of the FAME! speech corpus to quantify the quality of the automatic annotations. The ASR and CS detection results demonstrate the potential of using automatic language and speaker tagging in semi-supervised bilingual acoustic model training.	[Yilmaz, Emre; van den Heuvel, Henk; van Leeuwen, David A.] Radboud Univ Nijmegen, CLS CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands; [Yilmaz, Emre; McLaren, Mitchell] SRI Int, Speech Technol & Res Lab, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA	Radboud University Nijmegen; SRI International	Yilmaz, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.; Yilmaz, E (corresponding author), SRI Int, Speech Technol & Res Lab, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA.	einrey@kth.se; mitchell.mclaren@sri.com; h.vandenheuvel@let.ru.nl; d.vanleeuwen@let.ru.nl	; YILMAZ, EMRE/K-4777-2016	Van Leeuwen, David/0000-0001-9704-6141; van den Heuvel, Henk/0000-0003-2064-0630; YILMAZ, EMRE/0000-0001-7466-3358	NWO Project [314-99-119]; SRI International	NWO Project; SRI International	This research has been funded by the NWO Project 314-99-119 (Frisian Audio Mining Enterprise) and SRI International. We would like to thank Aaron Lawson for his support with the arrangement of this research visit; Martin Graciarena for his contributions to the speech activity detection system; Diego Castan for his contribution to the language diarization system; Mahesh Nandwana for his contribution to the speaker recognition system; Jelske Dijkstra and Hans Van de Velde for their contribution to the section on the Frisian language; and Frederik Kampstra for delivering the data from the Omrop Fryslan archive.		91	15	15	2	12	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	DEC	2018	105						12	22		10.1016/j.specom.2018.10.006	http://dx.doi.org/10.1016/j.specom.2018.10.006			11	Acoustics; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Acoustics; Computer Science	HH0PF		Green Submitted			2024-03-22	WOS:000455419600002
C	Xue, W; van Hout, R; Boogmans, F; Ganzeboom, M; Cucchiarini, C; Strik, H			Int Speech Commun Assoc	Xue, Wei; van Hout, Roeland; Boogmans, Fleur; Ganzeboom, Mario; Cucchiarini, Catia; Strik, Helmer			Speech intelligibility of dysarthric speech: human scores and acoustic-phonetic features	INTERSPEECH 2021	Interspeech		English	Proceedings Paper	Interspeech Conference	AUG 30-SEP 03, 2021	Brno, CZECH REPUBLIC			dysarthric speech; speech intelligibility; acoustic-phonetic features; speaker classification	SENTENCE INTELLIGIBILITY; PARKINSONS-DISEASE; SPEAKERS; LOUDNESS	We investigated speech intelligibility in dysarthric and non-dysarthric speakers as measured by two commonly used metrics, ratings through the Visual Analogue Scale (VAS) and word accuracy (AcW) through orthographic transcriptions. To gain a better understanding of how acoustic-phonetic correlates could be employed to obtain more objective measures of speech intelligibility and a better classification of dysarthric and non-dysarthric speakers, we studied the relation between these measures of intelligibility and some important acoustic-phonetic correlates. We found that the two intelligibility measures are related, but distinct, and that they might refer to different components of the intelligibility construct. The acoustic-phonetic features showed no difference in the mean values between the two speaker types at the utterance level, but more than half of them played a role in classifying the two speaker types. We computed an acoustic-phonetic probability index (API) at the speaker level. API is moderately correlated to VAS ratings but not correlated to AcW. In addition, API and VAS complement each other in classifying dysarthric and non-dysarthric speakers. This suggests that the intelligibility measures assigned by human raters and acoustic-phonetic features relate to different constructs of intelligibility.	[Xue, Wei; Cucchiarini, Catia; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [van Hout, Roeland; Boogmans, Fleur; Ganzeboom, Mario; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	w.xue@let.ru.nl; r.vanhout@let.ru.nl; fleurboogmans@live.nl; m.ganzeboom@let.ru.nl; c.cucchiarini@let.ru.nl; w.strik@let.ru.nl			European Union [766287]; Marie Curie Actions (MSCA) [766287] Funding Source: Marie Curie Actions (MSCA)	European Union(European Union (EU)); Marie Curie Actions (MSCA)(Marie Curie Actions)	This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 766287.		38	2	3	0	1	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2021							2911	2915		10.21437/Interspeech.2021-1189	http://dx.doi.org/10.21437/Interspeech.2021-1189			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT6JK		Green Published			2024-03-22	WOS:000841879502203
C	van den Heuvel, H; Kelli, A; Klessa, K; Salaasti, S		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		van den Heuvel, Henk; Kelli, Aleksei; Klessa, Katarzyna; Salaasti, Satu			Corpora of Disordered Speech in the Light of the GDPR: Two Use Cases from the DELAD Initiative	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			personal data; special categories of personal data; GDPR; language and speech disorders		Corpora of disordered speech (CDS) are costly to collect and difficult to share due to personal data protection and intellectual property (IP) issues. In this contribution we discuss the legal grounds for processing CDS in the light of the GDPR, and illustrate these with two use cases from the DELAD context. One use case deals with clinical datasets and another with legacy data from Polish hearing-impaired children. For both cases, processing based on consent and on public interest are taken into consideration.	[van den Heuvel, Henk] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Kelli, Aleksei] Univ Tartu, Sch Law, Tartu, Estonia; [Klessa, Katarzyna] Adam Mickiewicz Univ, Inst Appl Linguist, Poznan, Poland; [Salaasti, Satu] Univ Helsinki, Dept Psychol & Logoped, Helsinki, Finland	Radboud University Nijmegen; University of Tartu; Adam Mickiewicz University; University of Helsinki	Van den Heuvel, H (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.	h.vandenheuvel@letru.nl; aleksei.kelli@ut.ee; klessa@amu.edu.pl; satu.saalasti@helsinki.fi	Kelli, Aleksei/J-2986-2015	Klessa, Katarzyna/0000-0002-0419-2295; van den Heuvel, Henk/0000-0003-2064-0630					23	1	1	1	1	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							3317	3321						5	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697204038
J	Ganzeboom, M; Bakker, M; Beijer, L; Rietveld, T; Strik, H				Ganzeboom, Mario; Bakker, Marjoke; Beijer, Lilian; Rietveld, Toni; Strik, Helmer			Speech training for neurological patients using a serious game	BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY			English	Article							INTENSIVE VOICE TREATMENT; DISEASE	The majority of patients with neurological impairment like Parkinson's Disease (PD) or stroke are affected by dysarthria. Dysarthria is a motor speech impairment which negatively affects speech dimensions such as articulation and loudness. This leads to reduced intelligibility, often hindering daily life communication. Intensive and prolonged speech training can increase patients' speech intelligibility. Unfortunately, interventions by speech therapists are generally provided only for a short period of time, while continuing practice is needed to maintain or improve intelligibility. eHealth applications might provide a solution. In our research, we explored whether it is possible to develop a game that is suitable for providing speech training in elderly patients with dysarthria due to PD or stroke. In the game, we developed, called Treasure Hunters, two players interact verbally to find the way to the treasure, while receiving automatic feedback on voice loudness and pitch. Participants played with our game in several sessions and generally appreciated it, hinting at our game's potential for speech training in elderly patients. In a within-subjects experiment with five dysarthric patients, our game was compared to a non-game computer-based speech training system: e-learning-based Speech Therapy (EST). We focussed on three variables: speech intelligibility, user satisfaction and user preference. Substantial variability between participants was observed, in the outcomes of these three variables and their relations. We conclude that one size that fits all does not apply to computer-based speech training, but a personalised approach is needed.	[Ganzeboom, Mario; Bakker, Marjoke; Strik, Helmer] Radboud Univ Nijmegen, CLS CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands; [Bakker, Marjoke] HAN Univ Appl Sci, Arnhem, Netherlands; [Beijer, Lilian] HAN Univ Appl Sci, EHlth, Arnhem, Netherlands; [Beijer, Lilian] Sint Maartensklin Rehabil Ctr, Field Telerehabil, Nijmegen, Netherlands; [Rietveld, Toni] Radboud Univ Nijmegen, Methodol Speech & Language Pathol, Nijmegen, Netherlands; [Strik, Helmer] CHASING Project, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Ganzeboom, M (corresponding author), Radboud Univ Nijmegen, CLS CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.	m.ganzeboom@let.ru.nl	Strik, Helmer/I-8099-2012	Strik, Helmer/0000-0003-1722-3465	NWO research grant [314-99-101]	NWO research grant	This research was funded by the NWO research grant with Ref. no. 314-99-101 (CHASING).		22	7	7	2	24	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1013	1467-8535		BRIT J EDUC TECHNOL	Br. J. Educ. Technol.	JUL	2018	49	4			SI		761	774		10.1111/bjet.12640	http://dx.doi.org/10.1111/bjet.12640			14	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	GO6GF					2024-03-22	WOS:000440136700014
C	Yilmaz, E; Biswas, A; van der Westhuizen, E; de Wet, F; Niesler, T			Int Speech Commun Assoc	Yilmaz, Emre; Biswas, Astik; van der Westhuizen, Ewald; de Wet, Febe; Niesler, Thomas			Building a Unified Code-Switching ASR System for South African Languages	19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES	Interspeech		English	Proceedings Paper	19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018)	AUG 02-SEP 06, 2018	Hyderabad, INDIA	Int Speech Commun Assoc		code-switching; automatic speech recognition; multilinguality; South African languages	SPEECH RECOGNITION	We present our first efforts towards building a single multilingual automatic speech recognition (ASR) system that can process code-switching (CS) speech in five languages spoken within the same population. This contrasts with related prior work which focuses on the recognition of CS speech in bilingual scenarios. Recently, we have compiled a small five-language corpus of South African soap opera speech which contains examples of CS between 5 languages occurring in various contexts such as using English as the matrix language and switching to other indigenous languages. The ASR system presented in this work is trained on 4 corpora containing English-isiZulu, English-isiXhosa, English-Setswana and English-Sesotho CS speech. The interpolation of multiple language models trained on these language pairs enables the ASR system to hypothesize mixed word sequences from these 5 languages. We evaluate various state-of-the-art acoustic models trained on this 5-lingual training data and report ASR accuracy and language recognition performance on the development and test sets of the South African multilingual soap opera corpus.	[Yilmaz, Emre] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Yilmaz, Emre] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [Biswas, Astik; van der Westhuizen, Ewald; de Wet, Febe; Niesler, Thomas] Stellenbosch Univ, Dept Elect & Elect Engn, Stellenbosch, South Africa; [Yilmaz, Emre] Stellenbosch Univ, Stellenbosch, South Africa	Radboud University Nijmegen; National University of Singapore; Stellenbosch University; Stellenbosch University	Yilmaz, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.; Yilmaz, E (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.	e.yilmaz@let.ru.nl; abiswas@sun.ac.za; ewaldvdw@sun.ac.za; fdw@sun.ac.za; trn@sun.ac.za	YILMAZ, EMRE/K-4777-2016	YILMAZ, EMRE/0000-0001-7466-3358	NWO Project [314-99-119]; Department of Arts & Culture of the South African government; Stellenbosch University	NWO Project; Department of Arts & Culture of the South African government; Stellenbosch University	This research is funded by the NWO Project 314-99-119 (Frisian Audio Mining Enterprise). The authors would like to thank the Department of Arts & Culture of the South African government for funding this research as well as Stellenbosch University for the travel grant that enabled the first author's visit to Stellenbosch.		32	7	8	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X		978-1-5108-7221-9	INTERSPEECH			2018							1923	1927						5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BM5PH					2024-03-22	WOS:000465363900402
J	Xue, W; van Hout, R; Cucchiarini, C; Strik, H				Xue, Wei; van Hout, Roeland; Cucchiarini, Catia; Strik, Helmer			Assessing speech intelligibility of pathological speech in sentences and word lists: The contribution of phoneme-level measures	JOURNAL OF COMMUNICATION DISORDERS			English	Article						Speech intelligibility; Phoneme; Speaker type classification; Severity level classification; Interrater reliability; Validity	PARKINSONS-DISEASE; MULTIPLE-SCLEROSIS; DYSARTHRIC SPEECH; SPEAKERS; VOWEL; RELIABILITY; CHILDREN; SCORES; TRANSCRIPTION; AGREEMENT	Introduction: Speech intelligibility is an important indicator of the degree of speech impairment in pathological speech. Articulation, as a key feature of dysarthria, has been found to be a stronger contributor to intelligibility of dysarthric speech compared to voice quality, nasality, and prosody. In fact, therapy addressing articulation is often used by speech-language pathologists. Since phoneme-level measures are more directly related to articulation, they may contribute to better evaluating articulation imprecision in speakers with dysarthria and to monitoring the effectiveness of therapy.Method: We collected two types of phoneme-level measures: a) Accuracy of Phonemes, the percentage of correctly transcribed phonemes, and b) Phonetic Distance, from orthographic transcriptions obtained from expert raters in two types of speech materials (i.e., meaningful sentences and word lists). We first examined the measures' interrater reliability using Generalizability Theory. Then we studied the validity of the measures by correlating them to three criterion variables. Following this, we explored their ability in distinguishing speakers in two classification tasks according to speakers' types (i.e., healthy vs dysarthric) and their severity levels of dysarthria, respectively.Results: The results showed that both types of phoneme-level measures are highly reliable and valid in two different speech materials. They also showed acceptable results for both classification tasks in different speech materials, with word lists performing better than meaningful sentences. The differences between the two speech materials may be largely caused by differences in word structures and contextual cues in the materials.Conclusion: The results indicate that both types of phoneme-level measures show largely similar reliability and validity in both speech materials. These measures perform better in word lists than in meaningful sentences, suggesting an advantage for using word lists in clinical practice and research. On the other hand, meaningful sentences can be used for classifying healthy and dysarthric speakers. Our results suggest that using different speech materials gives a better overview of the speakers' intelligibility at the segmental level and the implications of their articulation impairments.	[Xue, Wei; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands; [van Hout, Roeland; Cucchiarini, Catia; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.	wei.xue@ru.nl		Xue, Wei/0000-0001-9498-3519	European Union [766287]	European Union(European Union (EU))	This work was supported by the European Union's Horizon 2020 research and innovation program under the Marie Sklodowska-Curie Grant number 766287.		65	0	0	1	2	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0021-9924	1873-7994		J COMMUN DISORD	J. Commun. Disord.	MAR-APR	2023	102								106301	10.1016/j.jcomdis.2023.106301	http://dx.doi.org/10.1016/j.jcomdis.2023.106301		JAN 2023	14	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	8P9NG	36709701	Green Published, hybrid			2024-03-22	WOS:000926842500001
J	van Krieken, K; Sanders, J				van Krieken, Kobie; Sanders, Jose			What is narrative journalism? A systematic review and an empirical agenda	JOURNALISM			English	Review						Genre; literary journalism; narrative journalism; news narrative; storytelling; subjectivity; systematic review	LITERARY JOURNALISM; CLIMATE-CHANGE; NEWS MEDIA; STORIES; FORMS; ADAPTATION; STRATEGIES; ETHICS; TRUST; SOUTH	This article reviews scientific research on narrative journalism, aiming to (1) demystify the nature of narrative journalism by specifying its core characteristics, resulting in a sustainable definition of the genre; (2) characterize the current state of the scientific field; and (3) identify gaps in our knowledge about narrative journalism. A systematic search of the scientific literature between 1998 and 2017 resulted in a set of 103 journal articles about narrative journalism. Their analysis reveals that the scientific field is dominated by essayistic and qualitative studies on printed forms of narrative journalism, with a focus on the history and style of narrative journalism, whereas systematic research on the function and impact of the genre is scarce. A framework is presented that synthesizes the hitherto isolated strands of research on narrative journalism and offers anchors for an empirical turn in narrative journalism studies.	[van Krieken, Kobie] Radboud Univ Nijmegen, Commun & Informat Studies, Ctr Language Studies, Nijmegen, Netherlands; [Sanders, Jose] Radboud Univ Nijmegen, Narrat Commun, CLS, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	van Krieken, K (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, POB 9103, NL-6500 HD Nijmegen, Netherlands.	k.vankrieken@let.ru.nl		van Krieken, Kobie/0000-0002-8578-9850	Innovational Research Incentives Scheme VENI grant from the Netherlands Organization for Scientific Research (NWO) [275-89-038]	Innovational Research Incentives Scheme VENI grant from the Netherlands Organization for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO))	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research was supported by an Innovational Research Incentives Scheme VENI grant from the Netherlands Organization for Scientific Research (NWO; project number 275-89-038) awarded to K.v.K.		73	24	25	13	79	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1464-8849	1741-3001		JOURNALISM	Journalism	JUN	2021	22	6					1393	1412	1464884919862056	10.1177/1464884919862056	http://dx.doi.org/10.1177/1464884919862056		JUL 2019	20	Communication	Social Science Citation Index (SSCI)	Communication	SF5ZJ		Green Published, hybrid			2024-03-22	WOS:000475058900001
J	Piepers, J; van de Groep, M; van Halteren, H; de Hoop, H				Piepers, Joske; van de Groep, Maria; van Halteren, Hans; de Hoop, Helen			"Amsterdam, you're raining!" First-hand experience in tweets with spatio-temporal addressees	JOURNAL OF PRAGMATICS			English	Article						Address; Construction; First-hand experience; Social media; Flexibility of grammar	FICTIVE INTERACTION; PERSPECTIVE; TWITTER; CONTEXT	The construction [X, you are/were Y], where X is a spatio-temporal addressee, is widely attested on Dutch social media. We investigated this construction in a Twitter corpus, and found that Twitter users use the construction to tell their audience about a current or recent experience at the location addressed, while at the same time evaluating said experience. Reference to this first-hand experience is not overtly expressed, yet it is an essential interpretive aspect of the construction. The grammatical components of the construction all contribute in their own way to this interpretation. Although the use of the vocative and the second person pronoun personify the spatio-temporal addressee to a certain degree, the addressee's spatio-temporal characteristics remain crucial, as they provide the background for the reported experience. It is noticeable that particular instances of the construction, which would be blatantly ungrammatical in other contexts, are now acceptable in virtue of these spatio-temporal characteristics of the fictive addressee. This reveals the flexibility of grammar, as it shows how grammar can adapt to the possibilities and limitations of social media use, and make otherwise ungrammatical utterances, such as 'you are raining', fully comprehensible. (C) 2021 The Authors. Published by Elsevier B.V.	[van de Groep, Maria; van Halteren, Hans; de Hoop, Helen] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Piepers, Joske] Tilburg Univ, Dept Culture Studies, Tilburg, Netherlands	Radboud University Nijmegen; Tilburg University	de Hoop, H (corresponding author), Radboud Univ Nijmegen, POB 9103, NL-6500 HD Nijmegen, Netherlands.	h.dehoop@let.ru.nl		Piepers, Joske/0000-0002-3253-9911; van Halteren, Hans/0000-0001-8115-1799; de Hoop, Helen/0000-0001-8652-1146					41	0	0	1	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0378-2166	1879-1387		J PRAGMATICS	J. Pragmat.	APR	2021	176						97	109		10.1016/j.pragma.2021.01.032	http://dx.doi.org/10.1016/j.pragma.2021.01.032		FEB 2021	13	Linguistics; Language & Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics	SF1GN		hybrid, Green Published			2024-03-22	WOS:000652511400009
C	Boelders, S; Nallanthigharl, VS; Menkovski, V; Härmä, A			IEEE	Boelders, Sander; Nallanthigharl, Venkata Srikanth; Menkovski, Vlado; Harma, Aki			DETECTION OF MILD DYSPNEA FROM PAIRS OF SPEECH RECORDINGS	2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 04-08, 2020	Barcelona, SPAIN	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers, Signal Proc Soc		Dyspnea; health monitoring; deep-learning; speech signal processing; data pairs		Shortness of breath, or dyspnea is a condition of the cardiopulmonary system that may be caused by, for example, a heart or lung disease, or physical load. In this paper, we explore techniques of detecting mild dyspnea directly from conversational speech, for example, in a telehealth application. We demonstrate with a collection of speech recordings before and after a light physical exercise that a siamese neural network, when presented examples of the two conditions, can detect the difference between two speech signals. This shows that this signal can be detected using data-pairs, removing the need for ratings of severity or the distinction of separate classes.	[Boelders, Sander; Nallanthigharl, Venkata Srikanth; Harma, Aki] Philips Research, Eindhoven, Netherlands; [Boelders, Sander; Menkovski, Vlado] Eindhoven Univ Technol, Eindhoven, Netherlands; [Nallanthigharl, Venkata Srikanth] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Philips; Philips Research; Eindhoven University of Technology; Radboud University Nijmegen	Boelders, S (corresponding author), Philips Research, Eindhoven, Netherlands.; Boelders, S (corresponding author), Eindhoven Univ Technol, Eindhoven, Netherlands.			Harma, Aki/0000-0002-2966-3305; Boelders, Sander/0000-0002-6540-1273					18	9	9	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-5090-6631-5	INT CONF ACOUST SPEE			2020							4102	4106		10.1109/icassp40776.2020.9054751	http://dx.doi.org/10.1109/icassp40776.2020.9054751			5	Acoustics; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Engineering	BQ7HU					2024-03-22	WOS:000615970404070
J	Hoeken, H; Boeijinga, A; Sanders, J				Hoeken, Hans; Boeijinga, Anniek; Sanders, Jose			The argument from example in health communication Persuading and enabling patients to live a healthier life	JOURNAL OF ARGUMENTATION IN CONTEXT			English	Article						argument from example; health communication; narrative persuasion	DUTCH TRUCK DRIVERS; ENTERTAINMENT-EDUCATION; STATISTICAL EVIDENCE; IDENTIFICATION; NARRATIVES; IMPACT; RISK; PERSUASIVENESS; PROMOTION; INTENTIONS	The argument from example is frequently used in health communication interventions. Some of these arguments are narrative in nature, in the sense that they relate a series of logically related events containing an experiencing agonist. In this article, research on narrative persuasion is discussed in order to show how such narrative arguments from examples can influence the target audience's beliefs about the possibility that a certain action will lead to certain consequences, the desirability of such consequences, as well as provide the target audience with ways by which to circumvent obstacles that prevent them from putting their intentions into actions. As such, narrative arguments from example can serve the needs of both people who still need to be motivated to change their behavior as those of people who already intend to adapt their behavior but fail to put this intention into action.	[Hoeken, Hans] Univ Utrecht, UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands; [Boeijinga, Anniek; Sanders, Jose] Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands	Utrecht University; Radboud University Nijmegen	Hoeken, H (corresponding author), Univ Utrecht, UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.	j.a.l.hoeken@uu.nl; anniekboeijinga@gmail.com; j.sanders@let.ru.nl	Hoeken, Hans/AAG-4376-2020						46	1	1	0	6	JOHN BENJAMINS PUBLISHING CO	AMSTERDAM	PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS	2211-4742	2211-4750		J ARGUM CONTEXT	J. Argum. Context	DEC 31	2018	7	3					249	265		10.1075/jaic.18046.hoe	http://dx.doi.org/10.1075/jaic.18046.hoe			17	Communication	Emerging Sources Citation Index (ESCI)	Communication	HK5TY		Green Submitted			2024-03-22	WOS:000458031800001
C	Bai, Y; Hubers, F; Cucchiarini, C; van Hout, R; Strik, H			Int Speech Commun Assoc	Bai, Yu; Hubers, Ferdy; Cucchiarini, Catia; van Hout, Roeland; Strik, Helmer			The Effects of Implicit and Explicit Feedback in an ASR-based Reading Tutor for Dutch First-graders	INTERSPEECH 2022	Interspeech		English	Proceedings Paper	Interspeech Conference	SEP 18-22, 2022	Incheon, SOUTH KOREA			reading tutor; speech recognition; decoding skills; feedback	ACQUISITION	Literacy skills are pivotal for children to become schooled and educated and to engage with written texts in everyday life. Learning to read is a primary skill that children acquire at school. Supervised, supportive guided reading aloud may help children improve their reading skills. However, such a supportive context is usually difficult to realize at school since teachers do not have enough time to give directed individual feedback. An ASR-based reading tutor could be a solution in such a pressing situation, as such a tutor can 'listen' to children reading, provide individual feedback on errors, and store information on reading practice into logfiles. In this study, we investigated the effectiveness of an ASR-based Reading Tutor for Dutch first graders, in which different forms of feedback were implemented. We collected data from 525 first-graders in 44 schools, with 263 pupils who received explicit feedback and 262 pupils who received implicit feedback. Analyses based on mixed linear regression models indicate positive effects of both feedback forms on reading accuracy and a trade-off relationship between accuracy and speed.	[Bai, Yu; Hubers, Ferdy; Cucchiarini, Catia; van Hout, Roeland; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [Hubers, Ferdy; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, Helmer] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Bai, Y (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	yu.bai@ru.nl; ferdy.hubers@ru.nl; catia.cucchiarini@ru.nl; roeland.vanhout@ru.nl; helmer.strik@ru.nl		Hubers, Ferdy/0000-0002-2298-6013	Dutch Research Council (NWO) [40.5.18540.121]	Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO))	This study was carried out within the 'Dutch ASR-based Reading Tutor' (DART) project (http://hstrik.ruhosting.nl/DART/).This work is part of the Netherlands Initiative for Education Research (NRO) and is funded by the Dutch Research Council (NWO) (project number 40.5.18540.121). We would like to thank our colleagues Marjoke Bakker, Erik van Schooten, and Rosemarie Irausquin, as well as all children who participated, their parents and teachers.		29	0	0	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2022							4476	4480		10.21437/Interspeech.2022-10810	http://dx.doi.org/10.21437/Interspeech.2022-10810			5	Acoustics; Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Audiology & Speech-Language Pathology; Computer Science; Engineering	BU4IZ					2024-03-22	WOS:000900724504132
C	Bai, Y; Hubers, F; Cucchiarini, C; Strik, H			Int Speech Commun Assoc	Bai, Yu; Hubers, Ferdy; Cucchiarini, Catia; Strik, Helmer			ASR-based Evaluation and Feedback for Individualized Reading Practice	INTERSPEECH 2020	Interspeech		English	Proceedings Paper	Interspeech Conference	OCT 25-29, 2020	Shanghai, PEOPLES R CHINA			reading tutor; child speech; ASR; log-files; accuracy; fluency; speed; individualized feedback		Learning to read is a prerequisite to participate in our knowledge society. Developing reading skills requires intensive practice with individual evaluation and guidance by teachers, which is not always feasible in traditional classroom instruction. Automatic Speech Recognition (ASR) technology could offer a solution, but so far it has been mostly used to follow children while reading and to provide correct word forms through text-to-speech technology. However, ASR could possibly be employed at earlier stages of learning to read when children are still in the process of developing decoding skills. Early evaluation through ASR and individualized feedback could help achieve more personalized and possibly more effective guidance, thus preventing reading problems and improving the process of reading development. In this paper we report on an explorative study in which an ASR-based system equipped with logging capabilities was developed and employed to evaluate decoding skills in Dutch first graders reading aloud, and to provide them with detailed, individualized feedback. The results indicate that ASR-based feedback leads to improved reading accuracy and speed and that the log-files provide useful information to enhance practice and feedback, thus paving the way for more personalized, technology-enriched approaches to reading instruction.	[Bai, Yu; Hubers, Ferdy; Cucchiarini, Catia; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [Hubers, Ferdy; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, Helmer] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Bai, Y (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	y.bai@let.ru.nl; f.hubers@let.ru.nl; c.cucchiarini@let.ru.nl; w.strik@let.ru.nl		Strik, Helmer/0000-0003-1722-3465; Hubers, Ferdy/0000-0002-2298-6013	Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO) [40.5.18540.121]; Dutch Organization for Scientific Research	Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO)(Netherlands Organization for Scientific Research (NWO)); Dutch Organization for Scientific Research(Netherlands Organization for Scientific Research (NWO))	We would like the thank our colleagues Marjoke Bakker and Erik van Schooten as well as our partners in the DART project [http://hstrik.ruhosting.nl/DART/]: NovoLearning [https://www.novo-learning.com/], esp. Joost van Doremalen and David van Leeuwen; and Zwijsen publishers [https://www.zwijsen.nl/], esp. Rosemarie Irausquin and Martin de Jong. Special thanks go to all the children who participated, their parents and their teachers. This work (project number 40.5.18540.121) is funded by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO), the Dutch Organization for Scientific Research.		21	1	1	1	2	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2020							3870	3874		10.21437/Interspeech.2020-2842	http://dx.doi.org/10.21437/Interspeech.2020-2842			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4QT					2024-03-22	WOS:000833594104002
C	Limonard, S; Cucchiarini, C; van Hout, RWNM; Strik, H			Int Speech Commun Assoc	Limonard, S.; Cucchiarini, C.; van Hout, R. W. N. M.; Strik, H.			Analyzing read aloud speech by primary school pupils: insights for research and development	INTERSPEECH 2020	Interspeech		English	Proceedings Paper	Interspeech Conference	OCT 25-29, 2020	Shanghai, PEOPLES R CHINA			child speech; read aloud; reading miscue index; reading proficiency; speech corpora		Reading software based on Automatic Speech Recognition (ASR) has been proposed as a possible supplement to traditional classroom instruction to help pupils achieve the required level of reading proficiency. However, the knowledge required to develop such software is not always available, especially for languages other than English. To this end, we analyzed a corpus containing speech material from Dutch native primary school pupils who read texts aloud at their mastery reading level. We investigated reading strategies, reading miscues, a novel reading miscue index and their relationship with AVI level (reading level) and gender. We found a significant effect of AVI level on reading miscue index, but did not find a decrease of reading miscue index as AVI level increased. Pupils mostly used lexical reading strategies, which seem to increase when AVI level increases. Miscues most frequently concerned low-frequency words with at least two syllables, and omitted and inserted words were generally high frequent, unstressed function words. These results provide insights that help design the content of reading interventions and that can contribute to developing and improving ASR-based reading software. We discuss the results in view of current trends in education and technology, and their implications for future research and development.	[Limonard, S.; Cucchiarini, C.; Strik, H.] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [van Hout, R. W. N. M.; Strik, H.] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, H.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Limonard, S (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	s.limonard@let.ru.nl; c.cucchiarini@let.ru.nl; r.vanhout@let.ru.nl; w.strik@let.ru.nl		Strik, Helmer/0000-0003-1722-3465					27	0	0	0	1	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2020							3710	3714		10.21437/Interspeech.2020-2804	http://dx.doi.org/10.21437/Interspeech.2020-2804			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4QT		Green Published			2024-03-22	WOS:000833594103170
J	Wei, X; Cucchiarini, C; van Hout, R; Strik, H				Wei, X.; Cucchiarini, C.; van Hout, R.; Strik, H.			Automatic Speech Recognition and Pronunciation Error Detection of Dutch Non-native Speech: cumulating speech resources in a pluricentric language	SPEECH COMMUNICATION			English	Article						Pluricentric languages; Automatic speech recognition; Transfer learning; Pronunciation error detection	MISPRONUNCIATION DETECTION	The shortage of large-scale learners' speech corpora and precise manual annotations are two major challenges for automatic L2 speech recognition and error detection in L2 speech, especially for non-dominant varieties of pluricentric languages. In these cases, collecting and annotating large non-native (L2 learner) corpora for all language varieties is often unattainable. In this study, we investigated ways of addressing these problems through conventional and transfer learning Deep Neural Network (DNN) based Automatic Speech Recognition (ASR) and ASR-based pronunciation error detection (PED) by cumulating Netherlandic Dutch and Flemish Dutch speech resources. First, we show that for ASR the baseline system can be improved by combining the Netherlandic Dutch and Flemish Dutch datasets. Next, through the knowledge learned from models trained on the Netherlandic Dutch data, the Flemish Dutch learners' ASR model can be further improved. In order to evaluate the perfor-mance of the PED algorithms in the absence of learner speech data with pronunciation error annotations, we introduced plausible pronunciation errors in the native corpora based on knowledge from Flemish learner speech, in order to simulate non-native speech errors. For PED we found that the results are much better for a GOP classifier trained on Flemish Dutch data than for one trained on Netherlandic Dutch data. PED produced worse results when the Netherlandic Dutch data were merged with the Flemish Dutch data, while for ASR, lower WERs were attained. Whether adding Netherlandic Dutch data to Flemish Dutch data is beneficial, thus seems to depend on the specific task the data are used for. We discuss these results, compare them to those of related research and suggest avenues for future research.	[Wei, X.; Cucchiarini, C.; Strik, H.] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [van Hout, R.; Strik, H.] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, H.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Radboud University Nijmegen	Wei, X (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.	xing.wei@ru.nl; catia.cucchiarini@ru.nl; roeland.vanhout@ru.nl; helmer.strik@ru.nl			China Scholarship Council (CSC)	China Scholarship Council (CSC)(China Scholarship Council)	The authors would like to acknowledge the financial support from the China Scholarship Council (CSC).		50	2	2	1	8	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	OCT	2022	144						1	9		10.1016/j.specom.2022.08.004	http://dx.doi.org/10.1016/j.specom.2022.08.004			9	Acoustics; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Acoustics; Computer Science	7U0CH		Green Published, hybrid			2024-03-22	WOS:000911805800001
J	de Graaf, A; Das, E				de Graaf, Anneke; Das, Enny			Portrayals of threatened needs and human virtue: a review of the content of eudaimonic entertainment	ANNALS OF THE INTERNATIONAL COMMUNICATION ASSOCIATION			English	Review						Eudaimonic entertainment; narrative content; fundamental needs; human virtue	MEDIA-INDUCED RECOVERY; MEANINGFUL ENTERTAINMENT; MEASUREMENT INVARIANCE; POLITICAL INTEREST; AFFECTIVE STATES; AGE-DIFFERENCES; EXPERIENCES; APPRECIATION; ENJOYMENT; ELEVATION	The present review examines whether commonalities and differences can be detected in the content of eudaimonic entertainment. We focused on two features: the fundamental human needs that were threatened, and the specific virtues that were portrayed. The results showed that the examined materials often included a combination of portrayals of threats to the fundamental human needs for safety, health and relatedness, and portrayals of the virtue of humanity, like love and kindness. Two subcategories could be distinguished in the materials, one in which the focus is on the portrayal of virtue as an answer to threatened needs, and one in which the focus is on the portrayal of threatened needs in which characters struggle even though they also have virtue.	[de Graaf, Anneke; Das, Enny] Radboud Univ Nijmegen, Ctr Language Studies CLS, Dept Language & Commun, Nijmegen, Netherlands; [de Graaf, Anneke] Radboud Univ Nijmegen, Ctr Language Studies, Dept Language & Commun, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen	de Graaf, A (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Dept Language & Commun, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.	anneke.degraaf@ru.nl		Das, Enny/0000-0002-0367-6757	Dutch Research Council (Nederlandse organisatie voor Wetenschappelijk Onderzoek (NWO)) [406.18.SW.039]	Dutch Research Council (Nederlandse organisatie voor Wetenschappelijk Onderzoek (NWO))(Netherlands Organization for Scientific Research (NWO))	This work was funded by the Dutch Research Council (Nederlandse organisatie voor Wetenschappelijk Onderzoek (NWO) Project no.: 406.18.SW.039).		113	0	0	0	0	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	2380-8985	2380-8977		ANN INT COMMUN ASSOC	Ann. Int. Commun. Assoc.	JAN 2	2023	47	1					55	83		10.1080/23808985.2022.2130811	http://dx.doi.org/10.1080/23808985.2022.2130811			29	Communication	Emerging Sources Citation Index (ESCI)	Communication	JF4Q7		hybrid, Green Published			2024-03-22	WOS:001171742600004
C	Yilmaz, E; Mitra, V; Bartels, C; Franco, H			Int Speech Commun Assoc	Yilmaz, Emre; Mitra, Vikramjit; Bartels, Chris; Franco, Horacio			Articulatory Features for ASR of Pathological Speech	19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES	Interspeech		English	Proceedings Paper	19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018)	AUG 02-SEP 06, 2018	Hyderabad, INDIA	Int Speech Commun Assoc		pathological speech; automatic speech recognition; articulatory features; convolutional neural networks; dysarthria	NEURAL-NETWORKS; INTELLIGIBILITY; RECOGNITION; PARAMETERS	In this work, we investigate the joint use of articulatory and acoustic features for automatic speech recognition (ASR) of pathological speech. Despite long-lasting efforts to build speaker- and text-independent ASR systems for people with dysarthria, the performance of state-of-the-art systems is still considerably lower on this type of speech than on normal speech. The most prominent reason for the inferior performance is the high variability in pathological speech that is characterized by the spectrotemporal deviations caused by articulatory impairments due to various etiologies. To cope with this high variation, we propose to use speech representations which utilize articulatory information together with the acoustic properties. A designated acoustic model, namely a fused-feature map convolutional neural network (fCNN), which performs frequency convolution on acoustic features and time convolution on articulatory features is trained and tested on a Dutch and a Flemish pathological speech corpus. The ASR performance of fCNN-based ASR system using joint features is compared to other neural network architectures such conventional CNNs and time-frequency convolutional networks (TFCNNs) in several training scenarios.	[Yilmaz, Emre] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Yilmaz, Emre] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [Mitra, Vikramjit] Univ Maryland, College Pk, MD 20742 USA; [Bartels, Chris; Franco, Horacio] SRI Int, STAR Lab, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA; [Mitra, Vikramjit] Apple Inc, Cupertino, CA 95014 USA	Radboud University Nijmegen; National University of Singapore; University System of Maryland; University of Maryland College Park; SRI International; Apple Inc	Yilmaz, E (corresponding author), Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands.; Yilmaz, E (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.	e.yilmaz@let.ru.nl; vmitra@umd.edu; chris.bartels@sri.com; horacio.franco@sri.com	YILMAZ, EMRE/K-4777-2016	YILMAZ, EMRE/0000-0001-7466-3358	NWO [314-99-101, 314-99-119]	NWO(Netherlands Organization for Scientific Research (NWO))	The second author is currently working with Apple Inc. This research is funded by the NWO Project 314-99-101 (CHASING) and NWO Project 314-99-119 (Frisian Audio Mining Enterprise).		43	8	8	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X		978-1-5108-7221-9	INTERSPEECH			2018							2958	2962						5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BM5PH					2024-03-22	WOS:000465363900617
J	Nallanthighal, VS; Mostaani, Z; Härmä, A; Strik, H; Magimai-Doss, M				Nallanthighal, Venkata Srikanth; Mostaani, Zohreh; Harma, Aki; Strik, Helmer; Magimai-Doss, Mathew			Deep learning architectures for estimating breathing signal and respiratory parameters from speech recordings	NEURAL NETWORKS			English	Article						Speech breathing; Signal processing; Deep neural networks; Respiratory parameters; Speech technology	AUTOMATIC DETECTION; NEURAL-NETWORKS; RIB CAGE; ENHANCEMENT; REGRESSION; FREQUENCY; ALGORITHM; VOLUME; END	Respiration is an essential and primary mechanism for speech production. We first inhale and then produce speech while exhaling. When we run out of breath, we stop speaking and inhale. Though this process is involuntary, speech production involves a systematic outflow of air during exhalation characterized by linguistic content and prosodic factors of the utterance. Thus speech and respiration are closely related, and modeling this relationship makes sensing respiratory dynamics directly from the speech plausible, however is not well explored. In this article, we conduct a comprehensive study to explore techniques for sensing breathing signal and breathing parameters from speech using deep learning architectures and address the challenges involved in establishing the practical purpose of this technology. Estimating the breathing pattern from the speech would give us information about the respiratory parameters, thus enabling us to understand the respiratory health using one's speech. (C) 2021 The Authors. Published by Elsevier Ltd.	[Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Mostaani, Zohreh; Magimai-Doss, Mathew] Idiap Res Inst, Martigny, Switzerland; [Mostaani, Zohreh] Ecole Polytech Fed Lausanne, Lausanne, Switzerland	Philips; Philips Research; Radboud University Nijmegen; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Nallanthighal, VS (corresponding author), Philips Res, Eindhoven, Netherlands.	srikanth.nallanthighal@philips.com		Mostaani, Zohreh/0000-0001-7369-4857; Magimai Doss, Mathew/0000-0002-8714-1409; Harma, Aki/0000-0002-2966-3305; Strik, Helmer/0000-0003-1722-3465	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project [766287]; Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS) [200021_188754]; Data Science Department, Philips Research, Eindhoven; Swiss National Science Foundation (SNF) [200021_188754] Funding Source: Swiss National Science Foundation (SNF)	Horizon H2020 Marie Skodowska-Curie Actions Initial Training Network European Training Network project; Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS)(Swiss National Science Foundation (SNSF)); Data Science Department, Philips Research, Eindhoven; Swiss National Science Foundation (SNF)(Swiss National Science Foundation (SNSF))	This document is partially supported by the Horizon H2020 Marie SkodowskaCurie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) , Data Science Department, Philips Research, Eindhoven and Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS) grant number 200021_188754.		60	13	13	0	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	SEP	2021	141						211	224		10.1016/j.neunet.2021.03.029	http://dx.doi.org/10.1016/j.neunet.2021.03.029		APR 2021	14	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Neurosciences & Neurology	TU6RV	33915446	Green Published, hybrid			2024-03-22	WOS:000681162400001
C	Xue, W; Ramos, VM; Harmsen, W; Cucchiarini, C; Van Hout, RWNM; Strik, H			Int Speech Commun Assoc	Xue, W.; Ramos, V. Mendoza; Harmsen, W.; Cucchiarini, C.; van Hout, R. W. N. M.; Strik, H.			Towards a comprehensive assessment of speech intelligibility for pathological speech	INTERSPEECH 2020	Interspeech		English	Proceedings Paper	Interspeech Conference	OCT 25-29, 2020	Shanghai, PEOPLES R CHINA			speech intelligibility; dysarthric speech; speech therapy; computational paralinguistic	DYSARTHRIA; SPEAKERS; RATINGS; SCORES	Speech intelligibility is an essential though complex construct in speech pathology. It is affected by multiple contextual variables and it is often measured in different ways. In this paper, we evaluate various measures of speech intelligibility based on orthographic transcriptions, with respect to their reliability and validity. For this study, different speech tasks were analyzed together with their respective perceptual ratings assigned by five experienced speech-language pathologists: a Visual Analogue Scale (VAS) and two types of orthographic transcriptions, one in terms of existing words and the other in terms of perceived segments, including nonsense words. Six subword measures concerning graphemes and phonemes were derived automatically from these transcriptions. All measures exhibit high degrees of reliability. Correlations between the six subword measures and three independent measures, VAS, word accuracy, and severity level, reveal that the measures extracted automatically from the orthographic transcriptions are valid predictors of speech intelligibility. The results also indicate differences between the speech tasks, suggesting that a comprehensive assessment of speech intelligibility requires materials from different speech tasks in combination with measures at different granularity levels: utterance, word, and subword. We discuss these results in relation to those of previous research and suggest possible avenues for future research.	[Xue, W.; Cucchiarini, C.; Strik, H.] Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands; [Ramos, V. Mendoza] Univ Hosp Antwerp, Dept Otorhinolaryngol Head & Neck Surg & Commun D, Antwerp, Belgium; [Harmsen, W.; van Hout, R. W. N. M.; Strik, H.] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Strik, H.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands	Radboud University Nijmegen; University of Antwerp; Radboud University Nijmegen; Radboud University Nijmegen	Xue, W (corresponding author), Radboud Univ Nijmegen, Ctr Language & Speech Technol CLST, Nijmegen, Netherlands.	w.xue@let.ru.nl; Viviana.MendozaRamos@uza.be; w.harmsen@student.ru.nl; c.cucchiarini@let.ru.nl; r.vanhout@let.ru.nl; w.strik@let.ru.nl			European Union [766287]; Marie Curie Actions (MSCA) [766287] Funding Source: Marie Curie Actions (MSCA)	European Union(European Union (EU)); Marie Curie Actions (MSCA)(Marie Curie Actions)	This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 766287. We would like to thank our colleagues from the Department of Otorhinolaryngology, Head and Neck Surgery and Communication Disorders of the University Hospital of Antwerp, Gwen Van Nuffelen and Marc De Bodt, for their cooperation and feedback.		31	3	3	0	1	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2020							3146	3150		10.21437/Interspeech.2020-2693	http://dx.doi.org/10.21437/Interspeech.2020-2693			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4QT		Green Published			2024-03-22	WOS:000833594103057
C	Biswas, A; de Wet, F; van der Westhuizen, E; Yzlmaz, E; Niesler, T			Int Speech Commun Assoc	Biswas, Astik; de Wet, Febe; van der Westhuizen, Ewald; Yzlmaz, Emre; Niesler, Thomas			Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech	19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES	Interspeech		English	Proceedings Paper	19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018)	AUG 02-SEP 06, 2018	Hyderabad, INDIA	Int Speech Commun Assoc		code-switching; under-resourced languages; African languages; speech recognition; DNN; TDNN-LSTM	RECOGNITION	Although isiZulu speakers code-switch with English as a matter of course, extremely little appropriate data is available for acoustic modelling. Recently, a small five-language corpus of code-switched South African soap opera speech was compiled. We used this corpus to evaluate the application of multilingual neural network acoustic modelling to English-isiZulu code-switched speech recognition. Our aim was to determine whether English-isiZulu speech recognition accuracy can be improved by incorporating three other language pairs in the corpus: English-isiXhosa, English-Setswana and English-Sesotho. Since isiXhosa, like isiZulu, belongs to the Nguni language family, while Setswana and Sesotho belong to the more distant Sotho family, we could also investigate the merits of additional data from within and across language groups. Our experiments using both fully connected DNN and TDNN-LSTM architectures show that English-isiZulu speech recognition accuracy as well as language identification after code-switching is improved more by the incorporation of English-isiXhosa data than by the incorporation of the other language pairs. However additional data from the more distant language group remained beneficial, and the best overall performance was always achieved with a multilingual neural network trained on all four language pairs.	[Biswas, Astik; de Wet, Febe; van der Westhuizen, Ewald; Niesler, Thomas] Stellenbosch Univ, Dept Elect & Elect Engn, Stellenbosch, South Africa; [Yzlmaz, Emre] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Yzlmaz, Emre] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore	Stellenbosch University; Radboud University Nijmegen; National University of Singapore	Biswas, A (corresponding author), Stellenbosch Univ, Dept Elect & Elect Engn, Stellenbosch, South Africa.	abiswas@sun.ac.za; fdw@sun.ac.za; ewaldvdw@sun.ac.za; e.yilmaz@let.ru.nl; trn@sun.ac.za	YILMAZ, EMRE/K-4777-2016	YILMAZ, EMRE/0000-0001-7466-3358	Department of Arts & Culture of the South African government; Stellenbosch University	Department of Arts & Culture of the South African government; Stellenbosch University	We would like to thank the Department of Arts & Culture of the South African government for funding this research and Stellenbosch University for the travel grant that enabled Dr Yilmaz to visit Stellenbosch. We are also indebted to Dr Armin Saeb and Dr Raghav Menon for their valuable insights. Finally, we gratefully acknowledge the support of the NVIDIA corporation for the donation of the GPU equipment used during this research.		33	1	1	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X		978-1-5108-7221-9	INTERSPEECH			2018							2603	2607		10.21437/Interspeech.2018-1711	http://dx.doi.org/10.21437/Interspeech.2018-1711			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BM5PH					2024-03-22	WOS:000465363900546
C	Mostaani, Z; Nallanthighal, VS; Härmä, A; Strik, H; Magimai-Doss, M			IEEE	Mostaani, Zohreh; Nallanthighal, Venkata Srikanth; Harma, Aki; Strik, Helmer; Magimai-Doss, Mathew			ON THE RELATIONSHIP BETWEEN SPEECH-BASED BREATHING SIGNAL PREDICTION EVALUATION MEASURES AND BREATHING PARAMETERS ESTIMATION	2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	JUN 06-11, 2021	ELECTR NETWORK	IEEE, Inst Elect & Elect Engineers, Signal Proc Soc		Respiratory parameters; Neural Networks; Speech breathing	VOLUME; END	The respiratory system is one of the major components of the speech production system. Any alteration in breathing can result in changes in speech. Specific breathing characteristics, such as breathing rate and tidal volume, can indicate a person's pathological condition. More recently, neural network-based methods have started emerging for predicting the breathing signal from the speech signal. The neural networks are trained and evaluated with different objective measures, such as mean squared error (MSE) and Pearson's correlation. This paper investigates whether there is a systematic relationship between the different objective measures used for training and evaluating the neural network models and the end-goal, i.e. estimation of breathing parameters such as, breathing rate and tidal volume. Our investigations on two different data sets with two different neural network-based approaches show that there is no clear systematic relationship. In other words, obtaining a high Pearson's correlation on the evaluation set does not necessarily mean better breathing parameter estimation. Thus, indicating the need for developing other objective evaluation measures.	[Mostaani, Zohreh; Magimai-Doss, Mathew] Idiap Res Inst, Martigny, Switzerland; [Mostaani, Zohreh] Ecole Polytech Fed Lausanne, Lausanne, Switzerland; [Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth; Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Philips; Philips Research; Radboud University Nijmegen	Mostaani, Z (corresponding author), Idiap Res Inst, Martigny, Switzerland.; Mostaani, Z (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.			Harma, Aki/0000-0002-2966-3305; Magimai Doss, Mathew/0000-0002-8714-1409	Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS) [200021 188754]; Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project [766287]; Data Science Department, Philips Research, Eindhoven; Swiss National Science Foundation (SNF) [200021_188754] Funding Source: Swiss National Science Foundation (SNF)	Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS)(Swiss National Science Foundation (SNSF)); Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project; Data Science Department, Philips Research, Eindhoven; Swiss National Science Foundation (SNF)(Swiss National Science Foundation (SNSF))	This work was partially supported by the Swiss National Science Foundation (SNSF) through the project Towards Integrated processing of Physiological and Speech signals (TIPS) grant number 200021 188754, and the Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network project under grant agreement No. 766287 (TAPAS) and Data Science Department, Philips Research, Eindhoven.		24	4	4	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-7281-7605-5				2021							1345	1349		10.1109/ICASSP39728.2021.9414756	http://dx.doi.org/10.1109/ICASSP39728.2021.9414756			5	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BS2OF		Green Submitted			2024-03-22	WOS:000704288401118
C	Yilmaz, E; Derinel, A; Zhou, K; van den Heuvel, H; Brummer, N; Li, HZ; van Leeuwen, DA			Int Speech Commun Assoc	Yilmaz, Emre; Derinel, Adem; Zhou, Kun; van den Heuvel, Henk; Brummer, Niko; Li, Haizhou; van Leeuwen, David A.			Large-Scale Speaker Diarization of Radio Broadcast Archives	INTERSPEECH 2019	Interspeech		English	Proceedings Paper	Interspeech Conference	SEP 15-19, 2019	Graz, AUSTRIA			Speaker diarization; speaker linking; speaker and cluster impurities; longitudinal broadcast data; x-vectors		This paper describes our initial efforts to build a large-scale speaker diarization (SD) and identification system on a recently digitized radio broadcast archive from the Netherlands which has more than 6500 audio tapes with 3000 hours of Frisian-Dutch speech recorded between 1950-2016. The employed large-scale diarization scheme involves two stages: (1) tape-level speaker diarization providing pseudo-speaker identities and (2) speaker linking to relate pseudo-speakers appearing in multiple tapes. Having access to the speaker models of several frequently appearing speakers from the previously collected FAME! speech corpus, we further perform speaker identification by linking these known speakers to the pseudo-speakers identified at the first stage. In this work, we present a recently created longitudinal and multilingual SD corpus designed for large-scale SD research and evaluate the performance of a new speaker linking system using x-vectors with PLDA to quantify cross-tape speaker similarity on this corpus. The performance of this speaker linking system is evaluated on a small subset of the archive which is manually annotated with speaker information. The speaker linking performance reported on this subset (53 hours) and the whole archive (3000 hours) is compared to quantify the impact of scaling up in the amount of speech data.	[Yilmaz, Emre; Derinel, Adem; Zhou, Kun; Li, Haizhou] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [van den Heuvel, Henk] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Brummer, Niko] Cyberupt BV, Johannesburg, South Africa; [van Leeuwen, David A.] Radboud Univ Nijmegen, ICIS, Nijmegen, Netherlands	National University of Singapore; Radboud University Nijmegen; Radboud University Nijmegen	Yilmaz, E (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.	emre@nus.edu.sg	Zhou, Kun/GOP-2478-2022; Li, Haizhou/Q-6438-2019; Zhou, Kun/ITT-3967-2023	Li, Haizhou/0000-0001-9158-9401	National Research Foundation through the AI Singapore Programme; AI Speech Lab: Automatic Speech Recognition for Public Service Project [AISG100E-2018-006]; NWO Project [314-99-119]	National Research Foundation through the AI Singapore Programme; AI Speech Lab: Automatic Speech Recognition for Public Service Project; NWO Project	This research is supported by National Research Foundation through the AI Singapore Programme, the AI Speech Lab: Automatic Speech Recognition for Public Service Project AISG100E-2018-006 and the NWO Project 314-99-119.		28	1	1	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2019							411	415		10.21437/Interspeech.2019-1399	http://dx.doi.org/10.21437/Interspeech.2019-1399			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4LP		Green Submitted			2024-03-22	WOS:000831796400083
C	Pan, YL; Nallanthighal, VS; Blackburn, D; Christensen, H; Härmä, A			IEEE	Pan, Yilin; Nallanthighal, Venkata Srikanth; Blackburn, Daniel; Christensen, Heidi; Harma, Aki			MULTI-TASK ESTIMATION OF AGE AND COGNITIVE DECLINE FROM SPEECH	2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	JUN 06-11, 2021	ELECTR NETWORK	IEEE, Inst Elect & Elect Engineers, Signal Proc Soc		Multi-task learning; age estimation; cognitive decline estimation; SincNet; x-vector	ALZHEIMERS-DISEASE	Speech is a common physiological signal that can be affected by both ageing and cognitive decline. Often the effect can be confounding, as would be the case for people at, e.g., very early stages of cognitive decline due to dementia. Despite this, the automatic predictions of age and cognitive decline based on cues found in the speech signal are generally treated as two separate tasks. In this paper, multi-task learning is applied for the joint estimation of age and the Mini-Mental Status Evaluation criteria (MMSE) commonly used to assess cognitive decline. To explore the relationship between age and MMSE, two neural network architectures are evaluated: a SincNet-based end-to-end architecture, and a system comprising of a feature extractor followed by a shallow neural network. Both are trained with single-task or multi-task targets. To compare, an SVM-based regressor is trained in a single-task setup. i-vector, x-vector and ComParE features are explored. Results are obtained on systems trained on the DementiaBank dataset and tested on an in-house dataset as well as the ADReSS dataset. The results show that both the age and MMSE estimation is improved by applying multi-task learning, with state-of-the-art results achieved on the ADReSS dataset acoustic-only task.	[Pan, Yilin; Christensen, Heidi] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England; [Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Nallanthighal, Venkata Srikanth] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands; [Blackburn, Daniel] Univ Sheffield, Sheffield Inst Translat Neurosci SITraN, Sheffield, S Yorkshire, England	University of Sheffield; Philips; Philips Research; Radboud University Nijmegen; University of Sheffield	Pan, YL (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.	yilin.pan@sheffield.ac.uk; aki.harma@philips.com	Blackburn, Daniel J/B-7355-2011	Christensen, Heidi/0000-0003-3028-5062; blackburn, daniel/0000-0001-8886-1283; Harma, Aki/0000-0002-2966-3305	European Union's H2020 Marie Sklodowska-Curie programme TAPAS (Training Network for PAthological Speech processing) [766287]	European Union's H2020 Marie Sklodowska-Curie programme TAPAS (Training Network for PAthological Speech processing)(European Union (EU))	This work is supported under the European Union's H2020 Marie Sklodowska-Curie programme TAPAS (Training Network for PAthological Speech processing; Grant Agreement No. 766287).		24	6	7	1	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-7281-7605-5				2021							7258	7262		10.1109/ICASSP39728.2021.9414642	http://dx.doi.org/10.1109/ICASSP39728.2021.9414642			5	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BS2OF					2024-03-22	WOS:000704288407107
C	Draxler, C; van den Heuvel, H; van Hessen, A; Calamai, S; Corti, L; Scagliola, S		Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mariani, J; Mazo, H; Moreno, A; Odijk, J; Piperidis, S		Draxler, Christoph; van den Heuvel, Henk; van Hessen, Arjan; Calamai, Silvia; Corti, Louise; Scagliola, Stefania			A CLARIN Transcription Portal for Interview Data	PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020)			English	Proceedings Paper	12th International Conference on Language Resources and Evaluation (LREC)	MAY 11-16, 2020	Marseille, FRANCE			automatic speech recognition; interviews; digital humanities; social sciences; research infrastructure		In this paper we present a first version of a transcription portal for audio files based on automatic speech recognition (ASR) in various languages. The portal is implemented in the CLARIN resources research network and intended for use by non-technical scholars. We explain the background and interdisciplinary nature of interview data, the perks and quirks of using ASR for transcribing the audio in a research context, the dos and don'ts for optimal use of the portal, and future developments foreseen. The portal is promoted in a range of workshops, but there are a number of challenges that have to be met. These challenges concern privacy issues, ASR quality, and cost, amongst others.	[Draxler, Christoph] BAS LMU, Munich, Germany; [van den Heuvel, Henk] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [van Hessen, Arjan] Univ Twente, Enschede, Netherlands; [Calamai, Silvia] Univ Siena, Siena, Italy; [Corti, Louise] Univ Essex, Colchester, Essex, England; [Scagliola, Stefania] Univ Luxembourg, Luxembourg, Luxembourg	University of Munich; Radboud University Nijmegen; University of Twente; University of Siena; University of Essex; University of Luxembourg	Draxler, C (corresponding author), BAS LMU, Munich, Germany.	draxler@phonetik.uni-muenchen.de; h.vandenheuvel@let.ru.nl; a.j.vanhessen@utwente.nl		van den Heuvel, Henk/0000-0003-2064-0630; Corti, Louise/0000-0002-6463-4358	CLARIN-EU	CLARIN-EU	The authors are grateful to CLARIN-EU for supporting the organization of the OH workshops and the implementation of the OH portal.		9	3	3	1	1	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-34-4				2020							3353	3359						7	Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS4ZZ					2024-03-22	WOS:000724697204043
C	Baur, C; Caines, A; Chua, C; Gerlach, J; Qian, MJ; Rayner, M; Russell, M; Strik, H; Wei, XZ			Int Speech Commun Assoc	Baur, Claudia; Caines, Andrew; Chua, Cathy; Gerlach, Johanna; Qian, Mengjie; Rayner, Manny; Russell, Martin; Strik, Helmer; Wei, Xizi			Overview of the 2018 Spoken CALL Shared Task	19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES	Interspeech		English	Proceedings Paper	19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018)	AUG 02-SEP 06, 2018	Hyderabad, INDIA	Int Speech Commun Assoc		CALL; shared tasks; speech recognition; metrics		We present an overview of the second edition of the Spoken CALL Shared Task. Groups competed on a prompt-response task using English-language data collected, through an online CALL game, from Swiss German teens in their second and third years of learning English. Each item consists of a written German prompt and an audio file containing a spoken response. The task is to accept linguistically correct responses and reject linguistically incorrect ones, with "linguistically correct" defined by a gold standard derived from human annotations. Scoring was performed using a metric defined as the ratio of the relative rejection rates on incorrect and correct responses. The second edition received eighteen entries and showed very substantial improvement on the first edition; all entries were better than the best entry from the first edition, and the best score was about four times higher. We present the task, the resources, the results, a discussion of the metrics used, and an analysis of what makes items challenging. In particular, we present quantitative evidence suggesting that incorrect responses are much more difficult to process than correct responses, and that the most significant factor in making a response challenging is its distance from the closest training example.	[Baur, Claudia; Gerlach, Johanna; Rayner, Manny] Univ Geneva, FTI TIM, Geneva, Switzerland; [Caines, Andrew] Univ Cambridge, Automated Language Teaching & Assessment Inst, Cambridge, England; [Qian, Mengjie; Russell, Martin; Wei, Xizi] Univ Birmingham, Dept Elect Elect & Syst Engn, Birmingham, W Midlands, England; [Strik, Helmer] Radboud Univ Nijmegen, CLS, Nijmegen, Netherlands	University of Geneva; University of Cambridge; University of Birmingham; Radboud University Nijmegen	Baur, C (corresponding author), Univ Geneva, FTI TIM, Geneva, Switzerland.	claudia.baur@bluewin.ch; apc38@cam.ac.uk; cathyc@pioneerbooks.com.au; Johanna.Gerlach@unige.ch; MXQ486@student.bham.ac.uk; Emmanuel.Rayner@unige.ch; m.j.russell@bham.ac.uk; w.strik@let.ru.nl; XXW395@student.bham.ac.uk	Strik, Helmer/I-8099-2012	Strik, Helmer/0000-0003-1722-3465	Swiss National Science Foundation [IZCOZO_177065]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF))	Work at Cambridge was funded by Cambridge Assessment English. Work at Geneva was partially funded by the Swiss National Science Foundation under grant IZCOZO_177065.		12	4	4	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X		978-1-5108-7221-9	INTERSPEECH			2018							2354	2358		10.21437/Interspeech.2018-97	http://dx.doi.org/10.21437/Interspeech.2018-97			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BM5PH		Green Published, Green Submitted			2024-03-22	WOS:000465363900493
J	Yilmaz, E; Mitra, V; Sivaraman, G; Franco, H				Yilmaz, Emre; Mitra, Vikramjit; Sivaraman, Ganesh; Franco, Horacio			Articulatory and bottleneck features for speaker-independent ASR of dysarthric speech	COMPUTER SPEECH AND LANGUAGE			English	Article						Pathological speech; Automatic speech recognition; Articulatory features; Time-frequency convolutional neural networks; Dysarthria	DEEP NEURAL-NETWORK; INTELLIGIBILITY; RECOGNITION; PARAMETERS; THERAPY; INDIVIDUALS; INTENSITY; KNOWLEDGE; STROKE; IMPACT	The rapid population aging has stimulated the development of assistive devices that provide personalized medical support to the needies suffering from various etiologies. One prominent clinical application is a computer-assisted speech training system which enables personalized speech therapy to patients impaired by communicative disorders in the patient's home environment. Such a system relies on the robust automatic speech recognition (ASR) technology to be able to provide accurate articulation feedback. With the long-term aim of developing off-the-shelf ASR systems that can be incorporated in clinical context without prior speaker information, we compare the ASR performance of speaker-independent bottleneck and articulatory features on dysarthric speech used in conjunction with dedicated neural network-based acoustic models that have been shown to be robust against spectrotemporal deviations. We report ASR performance of these systems on two dysarthric speech datasets of different characteristics to quantify the achieved performance gains. Despite the remaining performance gap between the dysarthric and normal speech, significant improvements have been reported on both datasets using speaker-independent ASR architectures. (C) 2019 Elsevier Ltd. All rights reserved.	[Yilmaz, Emre] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [Yilmaz, Emre] Radboud Univ Nijmegen, CLS CLST, Nijmegen, Netherlands; [Mitra, Vikramjit] Univ Maryland, College Pk, MD USA; [Sivaraman, Ganesh] Pindrop, Atlanta, GA USA; [Franco, Horacio] SRI Int, Star Lab, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA; [Mitra, Vikramjit] Apple Inc, Cupertino, CA 95014 USA	National University of Singapore; Radboud University Nijmegen; University System of Maryland; University of Maryland College Park; SRI International; Apple Inc	Yilmaz, E (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.	emre@nus.edu.sg; vmitra@umd.edu; horacio.franco@sri.com	P, Sivaraman/AAB-4336-2019; YILMAZ, EMRE/K-4777-2016	YILMAZ, EMRE/0000-0001-7466-3358; Sivaraman, Ganesh/0000-0002-5705-4443	NWO Project [314-99-119, 314-99-101]	NWO Project	This research is funded by the NWO Project 314-99-101 (CHASING) and NWO Project 314-99-119 (Frisian Audio Mining Enterprise).		65	15	15	0	37	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308	1095-8363		COMPUT SPEECH LANG	Comput. Speech Lang.	NOV	2019	58						319	334		10.1016/j.csl.2019.05.002	http://dx.doi.org/10.1016/j.csl.2019.05.002			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science	IM0GC		Green Submitted			2024-03-22	WOS:000477663800017
J	Larsson, T; Callies, M; Hasselgård, H; Laso, NJ; van Vuuren, S; Verdaguer, I; Paquot, M				Larsson, Tove; Callies, Marcus; Hasselgard, Hilde; Laso, Natalia Judith; van Vuuren, Sanne; Verdaguer, Isabel; Paquot, Magali			Adverb placement in EFL academic writing Going beyond syntactic transfer	INTERNATIONAL JOURNAL OF CORPUS LINGUISTICS			English	Article						adverb placement; novice writing; L2 writing; L1 transfer; learner corpus research	LEARNER; ENGLISH	The present study looks at adverb placement in expert writing and in first-language and second-language novice spoken and written production. The extent to which first-language (L1) transfer is still present in advanced learners' written production is also investigated. The study uses data from one expert corpus (LOCRA), two native-speaker student corpora (BAWE and LOCNEC) and two learner corpora (VESPA and LINDSEI). The results highlight the importance of taking mode into consideration, as clear distributional differences were found between spoken and written production. In addition, while considerable differences could be noted across L1 background in the spoken data, factors such as presence/absence of auxiliary, verb type (e.g. intransitive, copular/linking) and lexis were found to be most important for predicting adverb placement in the written data. Only very limited evidence of L1 transfer was found in the learners' writing, suggesting that advanced learners have largely mastered the distributional preferences of adverbs.	[Larsson, Tove] Uppsala Univ, Uppsala, Sweden; [Larsson, Tove; Paquot, Magali] UCLouvain, Louvain La Neuve, Belgium; [Callies, Marcus] Univ Bremen, Fac Linguist & Literary Studies English Speaking, Bremen, Germany; [Hasselgard, Hilde] Univ Oslo, Dept Literature Area Studies & European Languages, Oslo, Norway; [Laso, Natalia Judith; Verdaguer, Isabel] Univ Barcelona, Dept Modern Languages & Literatures & English Stu, Fac Philol & Commun, Barcelona, Spain; [van Vuuren, Sanne] Radboud Univ Nijmegen, CLS Dept Modern Languages & Cultures, Nijmegen, Netherlands; [Paquot, Magali] FNRS, Ctr English Corpus Linguist, Brussels, Belgium; [Paquot, Magali] Catholic Univ Louvain, Louvain La Neuve, Belgium	Uppsala University; Universite Catholique Louvain; University of Bremen; University of Oslo; University of Barcelona; Radboud University Nijmegen; Fonds de la Recherche Scientifique - FNRS; Universite Catholique Louvain	Larsson, T (corresponding author), Uppsala Univ, Dept English, Box 527, SE-75120 Uppsala, Sweden.	tove.larsson@engelska.uu.se	Larsson, Tove/JVP-1159-2024	Larsson, Tove/0000-0002-0489-2697; Hasselgard, Hilde/0000-0001-7764-0469; Callies, Marcus/0000-0002-7069-5819; Paquot, Magali/0000-0001-5687-5074					46	4	5	3	28	JOHN BENJAMINS PUBLISHING CO	AMSTERDAM	PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS	1384-6655	1569-9811		INT J CORPUS LINGUIS	Int. J. Corpus Linguist.		2020	25	2					155	184		10.1075/ijcl.19131.lar	http://dx.doi.org/10.1075/ijcl.19131.lar			30	Linguistics; Language & Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics	NS3RO		Green Submitted, hybrid, Green Published			2024-03-22	WOS:000572183200002
C	Cummins, N; Pan, YL; Ren, Z; Fritsch, J; Nallanthighal, VS; Christensen, H; Blackburn, D; Schuller, BW; Magimai-Doss, M; Strik, H; Härmä, A			Int Speech Commun Assoc	Cummins, Nicholas; Pan, Yilin; Ren, Zhao; Fritsch, Julian; Nallanthighal, Venkata Srikanth; Christensen, Heidi; Blackburn, Daniel; Schuller, Bjorn W.; Magimai-Doss, Mathew; Strik, Helmer; Harma, Aki			A Comparison of Acoustic and Linguistics Methodologies for Alzheimer's Dementia Recognition	INTERSPEECH 2020	Interspeech		English	Proceedings Paper	Interspeech Conference	OCT 25-29, 2020	Shanghai, PEOPLES R CHINA			Alzheimer's Disease; Bag-of-Audio-Words; Convolutional Neural Network; Siamese Network; Hierarchical Neural Network; Attention Mechanisms	NETWORK	In the light of the current COVID-19 pandemic, the need for remote digital health assessment tools is greater than ever. This statement is especially pertinent for elderly and vulnerable populations. In this regard, the INTERSPEECH 2020 Alzheimer's Dementia Recognition through Spontaneous Speech (ADReSS) Challenge offers competitors the opportunity to develop speech and language-based systems for the task of Alzheimer's Dementia (AD) recognition. The challenge data consists of speech recordings and their transcripts, the work presented herein is an assessment of different contemporary approaches on these modalities. Specifically, we compared a hierarchical neural network with an attention mechanism trained on linguistic features with three acoustic-based systems: (i) Bag-of-Audio-Words (BoAW) quantising different low-level descriptors, (ii) a Siamese Network trained on log-Mel spectrograms, and (iii) a Convolutional Neural Network (CNN) end-to-end system trained on raw waveforms. Key results indicate the strength of the linguistic approach over the acoustics systems. Our strongest test-set result was achieved using a late fusion combination of BoAW, End-to-End CNN, and hierarchical-attention networks, which outperformed the challenge baseline in both the classification and regression tasks.	[Cummins, Nicholas; Ren, Zhao; Schuller, Bjorn W.] Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, Augsburg, Germany; [Cummins, Nicholas] Kings Coll London, Dept Biostat & Hlth Informat, IoPPN, London, England; [Pan, Yilin; Christensen, Heidi] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England; [Fritsch, Julian; Magimai-Doss, Mathew] Idiap Res Inst, Martigny, Switzerland; [Fritsch, Julian] Ecole Polytech Fed Lausanne EPFL, Lausanne, Switzerland; [Nallanthighal, Venkata Srikanth; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Blackburn, Daniel] Univ Sheffield, Sheffield Inst Translat Neurosci SITraN, Sheffield, S Yorkshire, England; [Schuller, Bjorn W.] Imperial Coll London, GLAM Grp Language Audio & Mus, London, England; [Strik, Helmer] Radboud Univ Nijmegen, Ctr Language Studies CLS, Nijmegen, Netherlands	University of Augsburg; University of London; King's College London; University of Sheffield; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Philips; Philips Research; University of Sheffield; Imperial College London; Radboud University Nijmegen	Cummins, N (corresponding author), Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, Augsburg, Germany.; Cummins, N (corresponding author), Kings Coll London, Dept Biostat & Hlth Informat, IoPPN, London, England.	nicholas.cummins@leee.org	Blackburn, Daniel J/B-7355-2011	blackburn, daniel/0000-0001-8886-1283; Harma, Aki/0000-0002-2966-3305; Magimai Doss, Mathew/0000-0002-8714-1409; Christensen, Heidi/0000-0003-3028-5062	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network (MSCA-ITN-ETN) [766287]	Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network (MSCA-ITN-ETN)	This work was supported by the Horizon H2020 Marie Sklodowska-Curie Actions Initial Training Network European Training Network (MSCA-ITN-ETN) project under grant agreement No. 766287 (TAPAS). The four early stage researchers from the project: Yilin Pan, Zhao Ren, Julian Fritsch, and Srikanth Nallanthighal, all contributed equally to this manuscript.		32	34	34	0	2	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE	2308-457X			INTERSPEECH			2020							2182	2186		10.21437/Interspeech.2020-2635	http://dx.doi.org/10.21437/Interspeech.2020-2635			5	Audiology & Speech-Language Pathology; Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Audiology & Speech-Language Pathology; Computer Science	BT4QT		Green Accepted, Green Published			2024-03-22	WOS:000833594102063
